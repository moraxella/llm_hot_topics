{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImQtM4yH181r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pos9aRlZE0r",
        "outputId": "f1a5ac53-938e-48ff-9395-da06d1c43dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANG=en_US.UTF-8\n",
            "LANGUAGE=en_US\n",
            "LC_CTYPE=\"en_US.UTF-8\"\n",
            "LC_NUMERIC=\"en_US.UTF-8\"\n",
            "LC_TIME=\"en_US.UTF-8\"\n",
            "LC_COLLATE=\"en_US.UTF-8\"\n",
            "LC_MONETARY=\"en_US.UTF-8\"\n",
            "LC_MESSAGES=\"en_US.UTF-8\"\n",
            "LC_PAPER=\"en_US.UTF-8\"\n",
            "LC_NAME=\"en_US.UTF-8\"\n",
            "LC_ADDRESS=\"en_US.UTF-8\"\n",
            "LC_TELEPHONE=\"en_US.UTF-8\"\n",
            "LC_MEASUREMENT=\"en_US.UTF-8\"\n",
            "LC_IDENTIFICATION=\"en_US.UTF-8\"\n",
            "LC_ALL=en_US.UTF-8\n"
          ]
        }
      ],
      "source": [
        "# Set the locale to UTF-8 to resolve the encoding issue\n",
        "import os\n",
        "os.environ[\"LC_ALL\"] = \"en_US.UTF-8\"\n",
        "os.environ[\"LANG\"] = \"en_US.UTF-8\"\n",
        "\n",
        "# Check if the locale is set correctly\n",
        "!locale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6dN0PUoMVnx",
        "outputId": "dd7d458b-de2e-4f58-ccc8-d83bd6945e6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sP2ZH0J1NwRv"
      },
      "outputs": [],
      "source": [
        "!pip freeze > requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AqO-h5jaN2dc",
        "outputId": "08ba3280-026a-462d-c9b1-54d8f8c2906a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1b86f256-6b52-4d8b-8f32-7547b797e313\", \"requirements.txt\", 11643)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"requirements.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt3sbvHcORdj",
        "outputId": "b7c6fc35-4008-4970-b373-b92be97d0d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: torch: command not found\n"
          ]
        }
      ],
      "source": [
        "!torch --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR5B5oPK19RS"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy5rM7Lh2JnX"
      },
      "source": [
        "**Objective**\n",
        "\n",
        "Use Llama 2.0, Langchain and ChromaDB to create a Retrieval Augmented Generation (RAG) system. This will allow us to ask questions about our documents (that were not included in the training data), without fine-tunning the Large Language Model (LLM). When using RAG, if you are given a question, you first do a retrieval step to fetch any relevant documents from a special database, a vector database where these documents were indexed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY0Hs1wL2RKM"
      },
      "source": [
        "**Definitions**\n",
        "\n",
        "- LLM - Large Language Model\n",
        "\n",
        "- Llama 2.0 - LLM from Meta\n",
        "\n",
        "- Langchain - a framework designed to simplify the creation of applications using LLMs\n",
        "\n",
        "- Vector database - a database that organizes data through high-dimmensional vectors\n",
        "\n",
        "- ChromaDB - vector database\n",
        "\n",
        "- RAG - Retrieval Augmented Generation (see below more details about RAGs)\n",
        "\n",
        "LlaMA 2 model is pretrained and fine-tuned with 2 Trillion tokens and 7 to 70 Billion parameters which makes it one of the powerful open source models. It is a highly improvement over LlaMA 1 model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIx2Xpy-2jO-"
      },
      "source": [
        "**What is a Retrieval Augmented Generation (RAG) system?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_ngKLpL12fc"
      },
      "source": [
        "üîπ Think of RAG like a Smart AI Assistant with Internet Access! Instead of answering questions based only on what it \"remembers\" (like ChatGPT), RAG first retrieves relevant documents from a knowledge base and then uses that information to generate a response.\n",
        "\n",
        "üí° Analogy: RAG is like an Open-Book Exam üè´ Standard AI (LLMs like GPT-4) ‚Üí Answers only from memory (closed-book exam) üìñ RAG ‚Üí First looks up useful information, then answers (open-book exam)\n",
        "\n",
        "Implementing RAG - (Retrive auguented generation) Retrieval Augmented Generation combines external resources with LLMs. The main two components of a RAG are therefore a retriever and a generator.The retriver extracts the relevant information from the resources it acts like an encoder and genertor is responsible for the response via LLM by taking the context of those resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXaF7zPf3BOs"
      },
      "source": [
        "# Installations, imports, utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOQxIyVF1Lqk"
      },
      "source": [
        "Libraries that we're gonna used\n",
        "\n",
        "- transformers (4.33.0): Developed by Hugging Face, this library is one of the most popular for working with pre-trained models like GPT, BERT, T5, etc. It provides easy access to state-of-the-art natural language processing (NLP) models for tasks such as text generation, classification, translation, summarization, and more.\n",
        "\n",
        "- accelerate (0.22.0): This library is also from Hugging Face and is focused on optimizing training and inference workflows, especially for large models. It simplifies the process of using GPUs or multiple GPUs and distributed computing, helping speed up computations when working with deep learning models.\n",
        "\n",
        "- einops (0.6.1): A lightweight library for efficient tensor operations, particularly focusing on the transformation of tensors (multi-dimensional arrays). It provides simple, expressive, and high-performance ways to manipulate tensors, such as reshaping, permuting, and splitting them, making it useful in deep learning workflows.\n",
        "\n",
        "- langchain (0.0.300): As mentioned earlier, LangChain is a framework for building applications that integrate language models with other components, like databases, APIs, and external data sources. It's useful for creating sophisticated NLP applications, including chains, agents, memory, and data processing.\n",
        "\n",
        "- xformers (0.0.21): A library that provides implementations of various transformer-based architectures optimized for performance. Xformers aims to provide memory- and compute-efficient transformer layers, helping scale NLP models more efficiently, especially on large datasets.\n",
        "\n",
        "- bitsandbytes (0.41.1): This library is designed for low-precision training (quantization) and optimization of deep learning models. It helps reduce the memory usage of large models and speeds up training by using smaller numerical precisions like 8-bit integers.\n",
        "\n",
        "- sentence_transformers (2.2.2): This library is designed for sentence embeddings, allowing you to easily compute vector representations of sentences. It's widely used for tasks such as semantic textual similarity, clustering, and retrieval-based applications.\n",
        "\n",
        "- chromadb (0.4.12): ChromaDB is a vector database specifically built for managing embeddings. It allows you to store, query, and search over large sets of embeddings generated by models like sentence transformers. It‚Äôs often used in applications involving similarity search, like document retrieval or recommendation systems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XnU43qAh0WFn",
        "outputId": "77ad9cab-31ed-4557-a12d-68f75ab534ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.33.0 in /usr/local/lib/python3.11/dist-packages (4.33.0)\n",
            "Requirement already satisfied: accelerate==0.22.0 in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.11/dist-packages (0.6.1)\n",
            "Requirement already satisfied: langchain==0.0.300 in /usr/local/lib/python3.11/dist-packages (0.0.300)\n",
            "Requirement already satisfied: bitsandbytes==0.41.1 in /usr/local/lib/python3.11/dist-packages (0.41.1)\n",
            "Requirement already satisfied: sentence_transformers==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: chromadb==0.4.12 in /usr/local/lib/python3.11/dist-packages (0.4.12)\n",
            "Requirement already satisfied: wandb==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: pydantic==1.10.8 in /usr/local/lib/python3.11/dist-packages (1.10.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.33.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.22.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.22.0) (2.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (2.0.38)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (3.11.12)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (3.7.1)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (0.0.92)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (2.10.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.0.300) (8.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==2.2.2) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==2.2.2) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==2.2.2) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from sentence_transformers==2.2.2) (0.2.0)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (0.7.3)\n",
            "Requirement already satisfied: fastapi<0.100.0,>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (0.99.1)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (4.12.2)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (3.6.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (1.20.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (6.5.2)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.4.12) (0.15.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (8.1.8)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (3.1.44)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (2.22.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (75.1.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.16.0) (4.25.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<4.0->langchain==0.0.300) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<4.0->langchain==0.0.300) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb==0.16.0) (1.17.0)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12) (0.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.0) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2024.10.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (3.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (1.13.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.0) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.33.0) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate==0.22.0) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0) (3.31.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0) (18.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.12) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.4.12) (13.9.4)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (14.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->sentence_transformers==2.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence_transformers==2.2.2) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->sentence_transformers==2.2.2) (11.1.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.0) (5.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.12) (2.18.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.12) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.12) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 \\\n",
        "bitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12 wandb==0.16.0 pydantic==1.10.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efKMWqpNPGid",
        "outputId": "75d4f4e5-1e5e-46d9-ef53-756cadb471a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: torchaudio\n",
            "Version: 2.5.1+cu124\n",
            "Summary: An audio package for PyTorch\n",
            "Home-page: https://github.com/pytorch/audio\n",
            "Author: Soumith Chintala, David Pollack, Sean Naren, Peter Goldsborough, Moto Hira, Caroline Chen, Jeff Hwang, Zhaoheng Ni, Xiaohui Zhang\n",
            "Author-email: soumith@pytorch.org\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kwN907B30aiB"
      },
      "outputs": [],
      "source": [
        "# torch.cuda and bfloat16: Enable GPU acceleration and low-precision (bfloat16) training for faster and more memory-efficient deep learning.\n",
        "from torch import cuda, bfloat16\n",
        "\n",
        "# torch: Provides core tensor operations, which are essential for deep learning model manipulation and training.\n",
        "import torch\n",
        "\n",
        "# transformers: Hugging Face library to load pre-trained transformer models for various NLP tasks.\n",
        "import transformers\n",
        "\n",
        "# AutoTokenizer: Automatically loads the appropriate tokenizer for a pre-trained transformer model, enabling tokenization of text.\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# time: Used for measuring execution time, typically for performance benchmarking and timing operations.\n",
        "from time import time\n",
        "\n",
        "# langchain.llms.HuggingFacePipeline: Integrates Hugging Face transformer models into LangChain pipelines for advanced NLP applications.\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# langchain.document_loaders.TextLoader: Loads and processes documents from text files to feed into NLP models.\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# langchain.text_splitter.RecursiveCharacterTextSplitter: Splits long text documents into smaller chunks to make them manageable for processing.\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# langchain.embeddings.HuggingFaceEmbeddings: Uses Hugging Face models to generate vector embeddings (numerical representations) for text.\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# langchain.chains.RetrievalQA: Builds a question-answering system by retrieving relevant documents from a database and using a model to generate answers.\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# langchain.vectorstores.Chroma: Stores and retrieves vector embeddings efficiently, enabling similarity search for document retrieval.\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "from langchain.embeddings.base import Embeddings  # Import base class for custom embeddings\n",
        "\n",
        "from langchain.schema import Document  # Import Document class to structure text data\n",
        "\n",
        "import spacy  # Import spaCy for NLP processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKtyq_dUiQHE"
      },
      "source": [
        "# Initialize model, tokenizer, query pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGV0HZzuiV4N"
      },
      "source": [
        "Define the model, the device, and the bitsandbytes configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LXfYAbyIGcJM"
      },
      "outputs": [],
      "source": [
        "# model_id: Specifies the path or identifier for the pre-trained model stored in the specified directory.\n",
        "# This model is located in the `/kaggle/input/llama-2/pytorch/7b-chat-hf/1` directory and represents the LLaMA 2 model (7B variant),\n",
        "# which is a conversational model trained by Meta.\n",
        "# Use the smaller version of LLaMA 2 (3B)\n",
        "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "\n",
        "\n",
        "# device: Checks if a GPU is available using `cuda.is_available()` and selects the appropriate device.\n",
        "# If a GPU is available, it assigns the current CUDA device (`cuda:<device_id>`), otherwise, it defaults to CPU.\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# # bnb_config: Configures the settings for loading the model with reduced precision using quantization.\n",
        "# This setup helps reduce the GPU memory footprint by loading the model in a lower-precision format (4-bit).\n",
        "# It utilizes the `bitsandbytes` library, which allows efficient low-precision training and inference.\n",
        "# The configuration options:\n",
        "# - `load_in_4bit=True`: Load the model weights in 4-bit precision, reducing memory usage.\n",
        "# - `bnb_4bit_quant_type='nf4'`: Uses the \"Non-Uniform 4-bit\" (nf4) quantization type for compressing the model weights.\n",
        "# - `bnb_4bit_use_double_quant=True`: Enables the use of double quantization, which further improves memory efficiency.\n",
        "# - `bnb_4bit_compute_dtype=bfloat16`: Specifies that computations should use the `bfloat16` data type (16-bit precision) for lower memory usage during model inference.\n",
        "# This configuration is especially useful when working with large models that would otherwise be too large to fit into memory on a GPU.\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "__md0BcyeJSE",
        "outputId": "a7966fcb-86c1-437c-de7e-81f90ef297cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7HZUrYaiZUQ"
      },
      "source": [
        "Prepare the model and the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "f59507e1ae7449718146103d3a799681",
            "8fc84ed4fab74dd7bed261b2f206469e",
            "24d3c134225342fabcc2c097a2bc2424",
            "d5c5cc5037f544e9a85206fdc947a58f",
            "73757e578c6149fc83735b71d4aa6964",
            "b3ab7fca8b0e4966a39f84b8055cdc84",
            "283c8cd58ded4feabf2d0a42b7a47df1",
            "310c962da5a94162a1c0d74dd38af031",
            "df20603b16f1443d93d9dd58026e0ef7",
            "9d012603cec24b9b8407797555b209c1",
            "0e85ef268b78445e80cd984c62f64db7"
          ]
        },
        "id": "2cCVHL6BToHs",
        "outputId": "e725b50d-4183-4bb4-d8f3-b7902c5cff9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f59507e1ae7449718146103d3a799681",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepare model, tokenizer: 78.999 sec.\n"
          ]
        }
      ],
      "source": [
        "# model_id: Specifies the path or identifier for the pre-trained model stored in the specified directory.\n",
        "# This model is located in the `/kaggle/input/llama-2/pytorch/7b-chat-hf/1` directory and represents the LLaMA 2 model (7B variant),\n",
        "# which is a conversational model trained by Meta.\n",
        "# Use the smaller version of LLaMA 2 (3B)\n",
        "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "\n",
        "\n",
        "# device: Checks if a GPU is available using `cuda.is_available()` and selects the appropriate device.\n",
        "# If a GPU is available, it assigns the current CUDA device (`cuda:<device_id>`), otherwise, it defaults to CPU.\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# # bnb_config: Configures the settings for loading the model with reduced precision using quantization.\n",
        "# This setup helps reduce the GPU memory footprint by loading the model in a lower-precision format (4-bit).\n",
        "# It utilizes the `bitsandbytes` library, which allows efficient low-precision training and inference.\n",
        "# The configuration options:\n",
        "# - `load_in_4bit=True`: Load the model weights in 4-bit precision, reducing memory usage.\n",
        "# - `bnb_4bit_quant_type='nf4'`: Uses the \"Non-Uniform 4-bit\" (nf4) quantization type for compressing the model weights.\n",
        "# - `bnb_4bit_use_double_quant=True`: Enables the use of double quantization, which further improves memory efficiency.\n",
        "# - `bnb_4bit_compute_dtype=bfloat16`: Specifies that computations should use the `bfloat16` data type (16-bit precision) for lower memory usage during model inference.\n",
        "# This configuration is especially useful when working with large models that would otherwise be too large to fit into memory on a GPU.\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n",
        "\n",
        "\n",
        "# time_1: Captures the current time at the start of the model preparation process.\n",
        "# It is used for calculating the time taken to load the model and tokenizer.\n",
        "time_1 = time()\n",
        "\n",
        "# model_config: Loads the configuration settings for the pre-trained model from Hugging Face using the provided model_id.\n",
        "# This configuration includes hyperparameters and architecture settings necessary for the model.\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        ")\n",
        "\n",
        "# model: Loads the pre-trained model from Hugging Face using the provided model_id.\n",
        "# This also applies the quantization settings (`bnb_config`) to reduce memory usage and enables device placement (GPU/CPU).\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,  # Allows loading of custom code from the remote repository if needed.\n",
        "    config=model_config,  # Uses the configuration loaded earlier to correctly initialize the model.\n",
        "    quantization_config=bnb_config,  # Applies the quantization configuration (e.g., 4-bit loading) to reduce memory usage.\n",
        "    device_map='auto',  # Automatically places model layers across available devices (GPU/CPU).\n",
        ")\n",
        "\n",
        "# tokenizer: Loads the tokenizer associated with the pre-trained model.\n",
        "# Tokenizer is responsible for converting text into tokens (inputs for the model) and decoding model outputs back to human-readable text.\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# time_2: Captures the current time after the model and tokenizer have been loaded.\n",
        "# This helps in calculating the total time taken to prepare the model and tokenizer.\n",
        "time_2 = time()\n",
        "\n",
        "# Prints the time taken to prepare the model and tokenizer, rounded to 3 decimal places.\n",
        "print(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhccjEXqUxMT"
      },
      "source": [
        "Define the query pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZxndNhwfnax",
        "outputId": "920f5d72-9028-45a0-bedb-d731f93f631d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prepare pipeline: 1.009 sec.\n"
          ]
        }
      ],
      "source": [
        "# time_1: Captures the current time at the start of the pipeline preparation process.\n",
        "# This helps in calculating how much time it takes to prepare the pipeline.\n",
        "time_1 = time()\n",
        "\n",
        "# query_pipeline: Creates a text generation pipeline using the Hugging Face Transformers library.\n",
        "# This pipeline will generate text based on the input queries, such as a prompt or a question.\n",
        "query_pipeline = transformers.pipeline(\n",
        "    \"text-generation\",  # Specifies the task to be performed by the pipeline, which is text generation in this case.\n",
        "    model=model,  # Passes the pre-trained model (in this case, a causal language model like Llama).\n",
        "    tokenizer=tokenizer,  # Passes the tokenizer that corresponds to the model, responsible for tokenizing input text.\n",
        "    torch_dtype=torch.float16,  # Specifies the datatype for the model's weights. Using float16 for reduced memory usage and faster computation.\n",
        "    device_map=\"auto\",  # Automatically assigns model layers to available devices (GPU/CPU). This helps in multi-GPU environments.\n",
        ")\n",
        "\n",
        "# time_2: Captures the current time after the pipeline has been prepared.\n",
        "# This helps in calculating the total time taken to prepare the pipeline.\n",
        "time_2 = time()\n",
        "\n",
        "# Prints the time taken to prepare the pipeline, rounded to 3 decimal places.\n",
        "# This gives you an estimate of how long it took to load the model and set up the pipeline.\n",
        "print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpjpVL4U_ih"
      },
      "source": [
        "We define a function for testing the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aiBN1YgaVTWN"
      },
      "outputs": [],
      "source": [
        "def test_model(tokenizer, pipeline, prompt_to_test):\n",
        "    \"\"\"\n",
        "    Perform a query and print the result.\n",
        "\n",
        "    Args:\n",
        "        tokenizer: the tokenizer used to process input text (convert to tokens for the model).\n",
        "        pipeline: the pipeline that performs text generation (using a pre-trained model).\n",
        "        prompt_to_test: the input text (prompt) that will be used to generate text.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # adapted from https://huggingface.co/blog/llama2#using-transformers\n",
        "\n",
        "    # time_1: Captures the current time at the start of the text generation process.\n",
        "    # This will be used to calculate how long the inference (text generation) takes.\n",
        "    time_1 = time()\n",
        "\n",
        "    # sequences: Runs the pipeline to generate text based on the provided prompt.\n",
        "    # The `pipeline()` function returns a list of generated sequences.\n",
        "    sequences = pipeline(\n",
        "        prompt_to_test,  # The input prompt (text) used to generate the response.\n",
        "\n",
        "        # do_sample=True: Randomly samples from the distribution of possible tokens during generation,\n",
        "        # rather than picking the token with the highest probability (this makes output more diverse).\n",
        "        do_sample=True,\n",
        "\n",
        "        # top_k=10: Limits the token sampling to the top 10 most probable next tokens at each step.\n",
        "        # This adds randomness by restricting choices but still focusing on high probability tokens.\n",
        "        top_k=10,\n",
        "\n",
        "        # num_return_sequences=1: Specifies how many different sequences should be returned.\n",
        "        # In this case, it generates one sequence of text for the given prompt.\n",
        "        num_return_sequences=1,\n",
        "\n",
        "        # eos_token_id: The token that signals the end of the generated sequence.\n",
        "        # This is provided by the tokenizer, ensuring the model stops generating at an appropriate point.\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "\n",
        "        # max_length=200: Limits the maximum length of the generated sequence (in tokens).\n",
        "        # This helps avoid excessively long or infinite generation.\n",
        "        max_length=200,\n",
        "    )\n",
        "\n",
        "    # time_2: Captures the current time after the text generation is complete.\n",
        "    # This allows you to measure how long the inference process took.\n",
        "    time_2 = time()\n",
        "\n",
        "    # Prints the time it took to run the inference (text generation) process.\n",
        "    # The time difference is rounded to 3 decimal places for cleaner output.\n",
        "    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n",
        "\n",
        "    # For each sequence (output text) in the generated sequences list,\n",
        "    # print the resulting generated text.\n",
        "    for seq in sequences:\n",
        "        # seq['generated_text']: Access the generated text from the sequence (output).\n",
        "        print(f\"Result: {seq['generated_text']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzWvZ8-aVMpB"
      },
      "source": [
        "**Test the query pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkYErlVBVP_p"
      },
      "source": [
        "We test the pipeline with a query about the meaning of State of the Union (SOTU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K454c32yUzoa",
        "outputId": "7a4b95f7-a974-4dc6-da8f-b98250d0aa05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test inference: 8.325 sec.\n",
            "Result: Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\n",
            "The State of the Union address is an annual speech delivered by the President of the United States to a joint session of Congress, in which the President reviews the current state of the union, outlines policy goals and proposals, and seeks to rally and inspire the American people.\n"
          ]
        }
      ],
      "source": [
        "test_model(tokenizer,\n",
        "           query_pipeline,\n",
        "           \"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqHDFPpQVnh7"
      },
      "source": [
        "# Retrieval Augmented Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP8mWqR_VtTs"
      },
      "source": [
        "**Check the model with a HuggingFace pipeline**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeGOl2G5VwUG"
      },
      "source": [
        "We check the model with a HF pipeline, using a query about the meaning of State of the Union (SOTU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "aMo4D9HNVsOY",
        "outputId": "4edbe120-3f2b-45aa-b5cd-51a42e1e895e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\nThe State of the Union address is an annual speech given by the President of the United States to a joint session of Congress, in which the President reports on the current state of the union and outlines policy goals and legislative proposals for the upcoming year. The address is a key moment in the political calendar and is closely watched by lawmakers, the public, and the media.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# HuggingFacePipeline wraps the transformer pipeline created earlier into a LangChain-friendly object\n",
        "# 'query_pipeline' refers to a previously created pipeline with model and tokenizer set up for text generation.\n",
        "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
        "\n",
        "# Now we are testing the model to see if everything is working correctly\n",
        "# We are passing a prompt for the model to process and generate a response\n",
        "# The prompt here is asking for an explanation of the \"State of the Union address\" in 100 words.\n",
        "\n",
        "llm(prompt=\"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzmXVrcpWNy-"
      },
      "source": [
        "**Ingestion of data using Text loder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr0R7WRkWQjx"
      },
      "source": [
        "We will ingest the newest presidential address, from Jan 2023."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BU2YP7ucWYF2"
      },
      "outputs": [],
      "source": [
        "# Import the necessary module for loading text files\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Create an instance of the TextLoader class and specify the file path\n",
        "# \"/content/biden-sotu-2023-planned-official.txt\" - This is the text file to be loaded\n",
        "# encoding=\"utf8\" - Ensures that the file is read using UTF-8 encoding to handle special characters\n",
        "loader = TextLoader(\"/content/biden-sotu-2023-planned-official.txt\", encoding=\"utf8\")\n",
        "\n",
        "# Load the document into memory\n",
        "# This reads the file and stores its contents in a list of Document objects\n",
        "documents = loader.load()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hRngLB_PWne0",
        "outputId": "b188672e-ea8b-451c-90bc-4c46e4e23174"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Mr. Speaker. Madam Vice President. Our First Lady and Second Gentleman. Members of Congress and the Cabinet. Leaders of our military. Mr. Chief Justice, Associate Justices, and retired Justices of the Supreme Court. And you, my fellow Americans. I start tonight by congratulating the members of the 118th Congress and the new Speaker of the House, Kevin McCarthy. Mr. Speaker, I look forward to working together. I also want to congratulate the new leader of the House Democrats and the first Black House Minority Leader in history, Hakeem Jeffries. Congratulations to the longest serving Senate Leader in history, Mitch McConnell. And congratulations to Chuck Schumer for another term as Senate Majority Leader, this time with an even bigger majority. And I want to give special recognition to someone who I think will be considered the greatest Speaker in the history of this country, Nancy Pelosi. The story of America is a story of progress and resilience. Of always moving forward. Of never giving up. A story that is unique among all nations. We are the only country that has emerged from every crisis stronger than when we entered it. That is what we are doing again. Two years ago, our economy was reeling. As I stand here tonight, we have created a record 12 million new jobs, more jobs created in two years than any president has ever created in four years. Two years ago, COVID had shut down our businesses, closed our schools, and robbed us of so much. Today, COVID no longer controls our lives. And two years ago, our democracy faced its greatest threat since the Civil War. Today, though bruised, our democracy remains unbowed and unbroken. As we gather here tonight, we are writing the next chapter in the great American story, a story of progress and resilience. When world leaders ask me to define America, I define our country in one word: Possibilities. You know, we‚Äôre often told that Democrats and Republicans can‚Äôt work together. But over these past two years, we proved the cynics and the naysayers wrong. Yes, we disagreed plenty. And yes, there were times when Democrats had to go it alone. But time and again, Democrats and Republicans came together. Came together to defend a stronger and safer Europe. Came together to pass a once-in-a-generation infrastructure law, building bridges to connect our nation and people. Came together to pass one of the most significant laws ever, helping veterans exposed to toxic burn pits. In fact, I signed over 300 bipartisan laws since becoming President. From reauthorizing the Violence Against Women Act, to the Electoral Count Reform Act, to the Respect for Marriage Act that protects the right to marry the person you love. To my Republican friends, if we could work together in the last Congress, there is no reason we can‚Äôt work together in this new Congress. The people sent us a clear message. Fighting for the sake of fighting, power for the sake of power, conflict for the sake of conflict, gets us nowhere. And that‚Äôs always been my vision for our country. To restore the soul of the nation. To rebuild the backbone of America, the middle class. To unite the country. We‚Äôve been sent here to finish the job. For decades, the middle class was hollowed out. Too many good-paying manufacturing jobs moved overseas. Factories at home closed down. Once-thriving cities and towns became shadows of what they used to be. And along the way, something else was lost. Pride. That sense of self-worth. I ran for President to fundamentally change things, to make sure the economy works for everyone so we can all feel pride in what we do. To build an economy from the bottom up and the middle out, not from the top down. Because when the middle class does well, the poor have a ladder up and the wealthy still do very well. We all do well. As my Dad used to say, a job is about a lot more than a paycheck. It‚Äôs about your dignity. It‚Äôs about respect. It‚Äôs about being able to look your kid in the eye and say, ‚ÄúHoney ‚Äìit‚Äôs going to be OK,‚Äù and mean it. So, let‚Äôs look at the results. Unemployment rate at 3.4%, a 50-year low. Near record low unemployment for Black and Hispanic workers. We‚Äôve already created 800,000 good-paying manufacturing jobs, the fastest growth in 40 years. Where is it written that America can‚Äôt lead the world in manufacturing again? For too many decades, we imported products and exported jobs. Now, thanks to all we‚Äôve done, we‚Äôre exporting American products and creating American jobs. Inflation has been a global problem because of the pandemic that disrupted supply chains and Putin‚Äôs war that disrupted energy and food supplies. But we‚Äôre better positioned than any country on Earth. We have more to do, but here at home, inflation is coming down. Here at home, gas prices are down $1.50 a gallon since their peak. Food inflation is coming down. Inflation has fallen every month for the last six months while take home pay has gone up. Additionally, over the last two years, a record 10 million Americans applied to start a new small business. Every time somebody starts a small business, it‚Äôs an act of hope. And the Vice President will continue her work to ensure more small businesses can access capital and the historic laws we enacted. Standing here last year, I shared with you a story of American genius and possibility. Semiconductors, the small computer chips the size of your fingertip that power everything from cellphones to automobiles, and so much more. These chips were invented right here in America. America used to make nearly 40% of the world‚Äôs chips. But in the last few decades, we lost our edge and we‚Äôre down to producing only 10%. We all saw what happened during the pandemic when chip factories overseas shut down. Today‚Äôs automobiles need up to 3,000 chips each, but American automakers couldn‚Äôt make enough cars because there weren‚Äôt enough chips. Car prices went up. So did everything from refrigerators to cellphones. We can never let that happen again. That‚Äôs why we came together to pass the bipartisan CHIPS and Science Act. We‚Äôre making sure the supply chain for America begins in America. We‚Äôve already created 800,000 manufacturing jobs even without this law. With this new law, we will create hundreds of thousands of new jobs across the country. That‚Äôs going to come from companies that have announced more than $300 billion in investments in American manufacturing in the last two years. Outside of Columbus, Ohio, Intel is building semiconductor factories on a thousand acres ‚Äì a literal field of dreams. That‚Äôll create 10,000 jobs. 7,000 construction jobs. 3,000 jobs once the factories are finished. Jobs paying $130,000 a year, and many don‚Äôt require a college degree. Jobs where people don‚Äôt have to leave home in search of opportunity. And it‚Äôs just getting started. Think about the new homes, new small businesses, and so much more that will come to life. Talk to mayors and Governors, Democrats and Republicans, and they‚Äôll tell you what this means to their communities. We‚Äôre seeing these fields of dreams transform the heartland. But to maintain the strongest economy in the world, we also need the best infrastructure in the world. We used to be #1 in the world in infrastructure, then we fell to #13th. Now we‚Äôre coming back because we came together to pass the Bipartisan Infrastructure Law, the largest investment in infrastructure since President Eisenhower‚Äôs Interstate Highway System. Already, we‚Äôve funded over 20,000 projects, including at major airports from Boston to Atlanta to Portland. These projects will put hundreds of thousands of people to work rebuilding our highways, bridges, railroads, tunnels, ports and airports, clean water, and high-speed internet across America. Urban. Suburban. Rural. Tribal. And we‚Äôre just getting started. I sincerely thank my Republican friends who voted for the law. And to my Republican friends who voted against it but still ask to fund projects in their districts, don‚Äôt worry. I promised to be the president for all Americans. We‚Äôll fund your projects. And I‚Äôll see you at the ground-breaking. This law will help further unite all of America. Major projects like the Brent Spence bridge between Kentucky and Ohio over the Ohio River. Built 60 years ago. Badly in need of repairs. One of the nation‚Äôs most congested freight routes carrying $2 billion worth of freight every day. Folks have been talking about fixing it for decades, but we‚Äôre finally going to get it done. I went there last month with Democrats and Republicans from both states to deliver $1.6 billion for this project. While I was there, I met an ironworker named Sara, who is here tonight. For 30 years, she‚Äôs been a proud member of Ironworkers Local 44, known as the ‚Äúcowboys of the sky‚Äù who built the Cincinnati skyline. Sara said she can‚Äôt wait to be ten stories above the Ohio River building that new bridge. That‚Äôs pride. That‚Äôs what we‚Äôre also building ‚Äì Pride. We‚Äôre also replacing poisonous lead pipes that go into 10 million homes and 400,000 schools and childcare centers, so every child in America can drink clean water. We‚Äôre making sure that every community has access to affordable, high-speed internet. No parent should have to drive to a McDonald‚Äôs parking lot so their kid can do their homework online. And when we do these projects, we‚Äôre going to Buy American. Buy American has been the law of the land since 1933. But for too long, past administrations have found ways to get around it. Not anymore. Tonight, I‚Äôm also announcing new standards to require all construction materials used in federal infrastructure projects to be made in America. American-made lumber, glass, drywall, fiber optic cables. And on my watch, American roads, American bridges, and American highways will be made with American products. My economic plan is about investing in places and people that have been forgotten. Amid the economic upheaval of the past four decades, too many people have been left behind or treated like they‚Äôre invisible. Maybe that‚Äôs you, watching at home. You remember the jobs that went away. And you wonder whether a path even exists anymore for you and your children to get ahead without moving away. I get it. That‚Äôs why we‚Äôre building an economy where no one is left behind. Jobs are coming back, pride is coming back, because of the choices we made in the last two years. This is a blue-collar blueprint to rebuild America and make a real difference in your lives. For example, too many of you lay in bed at night staring at the ceiling, wondering what will happen if your spouse gets cancer, your child gets sick, or if something happens to you. Will you have the money to pay your medical bills? Will you have to sell the house? I get it. With the Inflation Reduction Act that I signed into law, we‚Äôre taking on powerful interests to bring your health care costs down so you can sleep better at night. You know, we pay more for prescription drugs than any major country on Earth. For example, one in ten Americans has diabetes. Every day, millions need insulin to control their diabetes so they can stay alive. Insulin has been around for 100 years. It costs drug companies just $10 a vial to make. But, Big Pharma has been unfairly charging people hundreds of dollars ‚Äì and making record profits. Not anymore. We capped the cost of insulin at $35 a month for seniors on Medicare. But there are millions of other Americans who are not on Medicare, including 200,000 young people with Type I diabetes who need insulin to save their lives. Let‚Äôs finish the job this time. Let‚Äôs cap the cost of insulin at $35 a month for every American who needs it. This law also caps out-of-pocket drug costs for seniors on Medicare at a maximum $2,000 per year when there are in fact many drugs, like expensive cancer drugs, that can cost up to $10,000, $12,000, and $14,000 a year. If drug prices rise faster than inflation, drug companies will have to pay Medicare back the difference. And we‚Äôre finally giving Medicare the power to negotiate drug prices. Bringing down prescription drug costs doesn‚Äôt just save seniors money. It will cut the federal deficit, saving tax payers hundreds of billions of dollars on the prescription drugs the government buys for Medicare. Why wouldn‚Äôt we want to do that? Now, some members here are threatening to repeal the Inflation Reduction Act. Make no mistake, if you try to do anything to raise the cost of prescription drugs, I will veto it. I‚Äôm pleased to say that more Americans have health insurance now than ever in history. A record 16 million people are enrolled under the Affordable Care Act. Thanks to the law I signed last year, millions are saving $800 a year on their premiums. But the way that law was written, that benefit expires after 2025. Let‚Äôs finish the job, make those savings permanent, and expand coverage to those left off Medicaid. Look, the Inflation Reduction Act is also the most significant investment ever to tackle the climate crisis. Lowering utility bills, creating American jobs, and leading the world to a clean energy future. I‚Äôve visited the devastating aftermaths of record floods and droughts, storms and wildfires. In addition to emergency recovery from Puerto Rico to Florida to Idaho, we are rebuilding for the long term. New electric grids able to weather the next major storm. Roads and water systems to withstand the next big flood. Clean energy to cut pollution and create jobs in communities too often left behind. We‚Äôre building 500,000 electric vehicle charging stations installed across the country by tens of thousands of IBEW workers. And helping families save more than $1,000 a year with tax credits for the purchase of electric vehicles and energy-efficient appliances. Historic conservation efforts to be responsible stewards of our lands. Let‚Äôs face reality. The climate crisis doesn‚Äôt care if your state is red or blue. It is an existential threat. We have an obligation to our children and grandchildren to confront it. I‚Äôm proud of how America is at last stepping up to the challenge. But there‚Äôs so much more to do. We will finish the job. And we pay for these investments in our future by finally making the wealthiest and the biggest corporations begin to pay their fair share. I‚Äôm a capitalist. But just pay your fair share. And I think a lot of you at home agree with me that our present tax system is simply unfair. The idea that in 2020, 55 of the biggest companies in America made $40 billion in profits and paid zero in federal income taxes? That‚Äôs simply not fair. But now, because of the law I signed, billion-dollar companies have to pay a minimum of 15%. Just 15%. That‚Äôs less than a nurse pays. Let me be clear. Under my plan, nobody earning less than $400,000 a year will pay an additional penny in taxes. Nobody. Not one penny. But there‚Äôs more to do. Let‚Äôs finish the job. Reward work, not just wealth. Pass my proposal for a billionaire minimum tax. Because no billionaire should pay a lower tax rate than a school teacher or a firefighter. You may have noticed that Big Oil just reported record profits. Last year, they made $200 billion in the midst of a global energy crisis. It‚Äôs outrageous. They invested too little of that profit to increase domestic production and keep gas prices down. Instead, they used those record profits to buy back their own stock, rewarding their CEOs and shareholders. Corporations ought to do the right thing. That‚Äôs why I propose that we quadruple the tax on corporate stock buybacks to encourage long term investments instead. They will still make a considerable profit. Let‚Äôs finish the job and close the loopholes that allow the very wealthy to avoid paying their taxes. Instead of cutting the number of audits of wealthy tax payers, I signed a law that will reduce the deficit by $114 billion by cracking down on wealthy tax cheats. That‚Äôs being fiscally responsible. In the last two years, my administration cut the deficit by more than $1.7 trillion ‚Äì the largest deficit reduction in American history. Under the previous administration, America‚Äôs deficit went up four years in a row. Because of those record deficits, no president added more to the national debt in any four years than my predecessor. Nearly 25% of the entire national debt, a debt that took 200 years to accumulate, was added by that administration alone. How did Congress respond to all that debt? They lifted the debt ceiling three times without preconditions or crisis. They paid America‚Äôs bills to prevent economic disaster for our country. Tonight, I‚Äôm asking this Congress to follow suit. Let us commit here tonight that the full faith and credit of the United States of America will never, ever be questioned. Some of my Republican friends want to take the economy hostage unless I agree to their economic plans. All of you at home should know what their plans are. Instead of making the wealthy pay their fair share, some Republicans want Medicare and Social Security to sunset every five years. That means if Congress doesn‚Äôt vote to keep them, those programs will go away. Other Republicans say if we don‚Äôt cut Social Security and Medicare, they‚Äôll let America default on its debt for the first time in our history. I won‚Äôt let that happen. Social Security and Medicare are a lifeline for millions of seniors. Americans have been paying into them with every single paycheck since they started working. So tonight, let‚Äôs all agree to stand up for seniors. Stand up and show them we will not cut Social Security. We will not cut Medicare. Those benefits belong to the American people. They earned them. If anyone tries to cut Social Security, I will stop them. And if anyone tries to cut Medicare, I will stop them. I will not allow them to be taken away. Not today. Not tomorrow. Not ever. Next month when I offer my fiscal plan, I ask my Republican friends to offer their plan. We can sit down together and discuss both plans together. My plan will lower the deficit by $2 trillion. I won‚Äôt cut a single Social Security or Medicare benefit. In fact, I will extend the Medicare Trust Fund by at least two decades. I will not raise taxes on anyone making under $400,000 a year. And I will pay for the ideas I‚Äôve talked about tonight by making the wealthy and big corporations begin to pay their fair share. Look, here‚Äôs the deal. Big corporations aren‚Äôt just taking advantage of the tax code. They‚Äôre taking advantage of you, the American consumer. Here‚Äôs my message to all of you out there: I have your back. We‚Äôre already preventing insurance companies from sending surprise medical bills, stopping 1 million surprise bills a month. We‚Äôre protecting seniors‚Äô lives and life savings by cracking down on nursing homes that commit fraud, endanger patient safety, or prescribe drugs they don‚Äôt need. Millions of Americans can now save thousands of dollars because they can finally get hearing aids over-the-counter without a prescription. Capitalism without competition is not capitalism. It is exploitation. Last year I cracked down on foreign shipping companies that were making you pay higher prices for everyday goods coming into our country. I signed a bipartisan bill that cut shipping costs by 90%, helping American farmers, businesses, and consumers. Let‚Äôs finish the job. Pass bipartisan legislation to strengthen antitrust enforcement and prevent big online platforms from giving their own products an unfair advantage. My administration is also taking on ‚Äújunk‚Äù fees, those hidden surcharges too many businesses use to make you pay more. For example, we‚Äôre making airlines show you the full ticket price upfront and refund your money if your flight is cancelled or delayed. We‚Äôve reduced exorbitant bank overdraft fees, saving consumers more than $1 billion a year. We‚Äôre cutting credit card late fees by 75%, from $30 to $8. Junk fees may not matter to the very wealthy, but they matter to most folks in homes like the one I grew up in. They add up to hundreds of dollars a month. They make it harder for you to pay the bills or afford that family trip. I know how unfair it feels when a company overcharges you and gets away with it. Not anymore. We‚Äôve written a bill to stop all that. It‚Äôs called the Junk Fee Prevention Act. We‚Äôll ban surprise ‚Äúresort fees‚Äù that hotels tack on to your bill. These fees can cost you up to $90 a night at hotels that aren‚Äôt even resorts. We‚Äôll make cable internet and cellphone companies stop charging you up to $200 or more when you decide to switch to another provider. We‚Äôll cap service fees on tickets to concerts and sporting events and make companies disclose all fees upfront. And we‚Äôll prohibit airlines from charging up to $50 roundtrip for families just to sit together. Baggage fees are bad enough ‚Äì they can‚Äôt just treat your child like a piece of luggage. Americans are tired of being played for suckers. Pass the Junk Fee Prevention Act so companies stop ripping us off. For too long, workers have been getting stiffed. Not anymore. We‚Äôre beginning to restore the dignity of work. For example, 30 million workers had to sign non-compete agreements when they took a job. So a cashier at a burger place can‚Äôt cross the street to take the same job at another burger place to make a couple bucks more. Not anymore. We‚Äôre banning those agreements so companies have to compete for workers and pay them what they‚Äôre worth. I‚Äôm so sick and tired of companies breaking the law by preventing workers from organizing. Pass the PRO Act because workers have a right to form a union. And let‚Äôs guarantee all workers a living wage. Let‚Äôs also make sure working parents can afford to raise a family with sick days, paid family and medical leave, and affordable child care that will enable millions more people to go to work. Let‚Äôs also restore the full Child Tax Credit, which gave tens of millions of parents some breathing room and cut child poverty in half, to the lowest level in history. And by the way, when we do all of these things, we increase productivity. We increase economic growth. Let‚Äôs also finish the job and get more families access to affordable and quality housing. Let‚Äôs get seniors who want to stay in their homes the care they need to do so. And give a little more breathing room to millions of family caregivers looking after their loved ones. Pass my plan so we get seniors and people with disabilities the home care services they need and support the workers who are doing God‚Äôs work. These plans are fully paid for and we can afford to do them. Restoring the dignity of work also means making education an affordable ticket to the middle class. When we made 12 years of public education universal in the last century, it made us the best-educated, best-prepared nation in the world. But the world has caught up. Jill, who teaches full-time, has an expression: ‚ÄúAny nation that out-educates us will out-compete us.‚Äù Folks, you all know 12 years is not enough to win the economic competition for the 21st Century. If you want America to have the best-educated workforce, let‚Äôs finish the job by providing access to pre-school for 3- and 4-year-olds. Studies show that children who go to pre-school are nearly 50% more likely to finish high school and go on to earn a 2- or 4-year degree, no matter their background. Let‚Äôs give public school teachers a raise. And we‚Äôre making progress by reducing student debt and increasing Pell Grants for working- and middle-class families. Let‚Äôs finish the job, connect students to career opportunities starting in high school and provide two years of community college, some of the best career training in America, in addition to being a pathway to a four-year degree. Let‚Äôs offer every American the path to a good career whether they go to college or not. And folks, in the midst of the COVID crisis when schools were closed, let‚Äôs also recognize how far we‚Äôve come in the fight against the pandemic itself. While the virus is not gone, thanks to the resilience of the American people, we have broken COVID‚Äôs grip on us. COVID deaths are down nearly 90%. We‚Äôve saved millions of lives and opened our country back up. And soon we‚Äôll end the public health emergency. But we will remember the toll and pain that will never go away for so many. More than 1 million Americans have lost their lives to COVID. Families grieving. Children orphaned. Empty chairs at the dining room table. We remember them, and we remain vigilant. We still need to monitor dozens of variants and support new vaccines and treatments. So Congress needs to fund these efforts and keep America safe. And as we emerge from this crisis stronger, I‚Äôm also doubling down on prosecuting criminals who stole relief money meant to keep workers and small businesses afloat during the pandemic. Before I came to office many inspector generals who protect taxpayer dollars were sidelined. Fraud was rampant. Last year, I told you the watchdogs are back. Since then, we‚Äôve recovered billions of taxpayer dollars. Now, let‚Äôs triple our anti-fraud strike forces going after these criminals, double the statute of limitations on these crimes, and crack down on identity fraud by criminal syndicates stealing billions of dollars from the American people. For every dollar we put into fighting fraud, taxpayers get back at least ten times as much. COVID left other scars, like the spike in violent crime in 2020, the first year of the pandemic. We have an obligation to make sure all our people are safe. Public safety depends on public trust. But too often that trust is violated. Joining us tonight are the parents of Tyre Nichols, who had to bury him just last week. There are no words to describe the heartbreak and grief of losing a child. But imagine what it‚Äôs like to lose a child at the hands of the law. Imagine having to worry whether your son or daughter will come home from walking down the street or playing in the park or just driving their car. I‚Äôve never had to have the talk with my children ‚Äì Beau, Hunter, and Ashley ‚Äì that so many Black and Brown families have had with their children. If a police officer pulls you over, turn on your interior lights. Don‚Äôt reach for your license. Keep your hands on the steering wheel. Imagine having to worry like that every day in America. Here‚Äôs what Tyre‚Äôs mom shared with me when I asked her how she finds the courage to carry on and speak out. With faith in God, she said her son ‚Äúwas a beautiful soul and something good will come from this.‚Äù Imagine how much courage and character that takes. It‚Äôs up to us. It‚Äôs up to all of us. We all want the same thing. Neighborhoods free of violence. Law enforcement who earn the community‚Äôs trust. Our children to come home safely. Equal protection under the law; that‚Äôs the covenant we have with each other in America. And we know police officers put their lives on the line every day, and we ask them to do too much. To be counselors, social workers, psychologists; responding to drug overdoses, mental health crises, and more. We ask too much of them. I know most cops are good, decent people. They risk their lives every time they put on that shield. But what happened to Tyre in Memphis happens too often. We have to do better. Give law enforcement the training they need, hold them to higher standards, and help them succeed in keeping everyone safe. We also need more first responders and other professionals to address growing mental health and substance abuse challenges. More resources to reduce violent crime and gun crime; more community intervention programs; more investments in housing, education, and job training. All this can help prevent violence in the first place. And when police officers or departments violate the public‚Äôs trust, we must hold them accountable. With the support of families of victims, civil rights groups, and law enforcement, I signed an executive order for all federal officers banning chokeholds, restricting no-knock warrants, and other key elements of the George Floyd Act. Let‚Äôs commit ourselves to make the words of Tyre‚Äôs mother come true, something good must come from this. All of us in this chamber, we need to rise to this moment. We can‚Äôt turn away. Let‚Äôs do what we know in our hearts we need to do. Let‚Äôs come together and finish the job on police reform. Do something. That was the same plea of parents who lost their children in Uvalde: Do something on gun violence. Thank God we did, passing the most sweeping gun safety law in three decades. That includes things that the majority of responsible gun owners support, like enhanced background checks for 18 to 21-year-olds and red flag laws keeping guns out of the hands of people who are a danger to themselves and others. But we know our work is not done. Joining us tonight is Brandon Tsay, a 26-year-old hero. Brandon put off his college dreams to stay by his mom‚Äôs side as she was dying from cancer. He now works at a dance studio started by his grandparents. Two weeks ago, during Lunar New Year celebrations, he heard the studio‚Äôs front door close and saw a man pointing a gun at him. He thought he was going to die, but then he thought about the people inside. In that instant, he found the courage to act and wrestled the semi-automatic pistol away from a gunman who had already killed 11 people at another dance studio. He saved lives. It‚Äôs time we do the same as well. Ban assault weapons once and for all. We did it before. I led the fight to ban them in 1994. In the 10 years the ban was law, mass shootings went down. After Republicans let it expire, mass shootings tripled. Let‚Äôs finish the job and ban assault weapons again. And let‚Äôs also come together on immigration and make it a bipartisan issue like it was before. We now have a record number of personnel working to secure the border, arresting 8,000 human smugglers and seizing over 23,000 pounds of fentanyl in just the last several months. Since we launched our new border plan last month, unlawful migration from Cuba, Haiti, Nicaragua, and Venezuela has come down 97%. But America‚Äôs border problems won‚Äôt be fixed until Congress acts. If you won‚Äôt pass my comprehensive immigration reform, at least pass my plan to provide the equipment and officers to secure the border. And a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. Here in the people‚Äôs House, it‚Äôs our duty to protect all the people‚Äôs rights and freedoms. Congress must restore the right the Supreme Court took away last year and codify Roe v. Wade to protect every woman‚Äôs constitutional right to choose. The Vice President and I are doing everything we can to protect access to reproductive health care and safeguard patient privacy. But already, more than a dozen states are enforcing extreme abortion bans. Make no mistake; if Congress passes a national abortion ban, I will veto it. Let‚Äôs also pass the bipartisan Equality Act to ensure LGBTQ Americans, especially transgender young people, can live with safety and dignity. Our strength is not just the example of our power, but the power of our example. Let‚Äôs remember the world is watching. I spoke from this chamber one year ago, just days after Vladimir Putin unleashed his brutal war against Ukraine. A murderous assault, evoking images of the death and destruction Europe suffered in World War II. Putin‚Äôs invasion has been a test for the ages. A test for America. A test for the world. Would we stand for the most basic of principles? Would we stand for sovereignty? Would we stand for the right of people to live free from tyranny? Would we stand for the defense of democracy? For such a defense matters to us because it keeps the peace and prevents open season for would-be aggressors to threaten our security and prosperity. One year later, we know the answer. Yes, we would. And yes, we did. Together, we did what America always does at our best. We led. We united NATO and built a global coalition. We stood against Putin‚Äôs aggression. We stood with the Ukrainian people. Tonight, we are once again joined by Ukraine‚Äôs Ambassador to the United States. She represents not just her nation, but the courage of her people. Ambassador, America is united in our support for your country. We will stand with you as long as it takes. Our nation is working for more freedom, more dignity, and more peace,not just in Europe, but everywhere. Before I came to office, the story was about how the People‚Äôs Republic of China was increasing its power and America was falling in the world. Not anymore. I‚Äôve made clear with President Xi that we seek competition, not conflict. I will make no apologies that we are investing to make America strong. Investing in American innovation, in industries that will define the future, and that China‚Äôs government is intent on dominating. Investing in our alliances and working with our allies to protect our advanced technologies so they‚Äôre not used against us. Modernizing our military to safeguard stability and deter aggression. Today, we‚Äôre in the strongest position in decades to compete with China or anyone else in the world. I am committed to work with China where it can advance American interests and benefit the world. But make no mistake: as we made clear last week, if China‚Äôs threatens our sovereignty, we will act to protect our country. And we did. And let‚Äôs be clear: winning the competition with China should unite all of us. We face serious challenges across the world. But in the past two years, democracies have become stronger, not weaker. Autocracies have grown weaker, not stronger. America is rallying the world again to meet those challenges, from climate and global health, to food insecurity, to terrorism and territorial aggression. Allies are stepping up, spending more and doing more. And bridges are forming between partners in the Pacific and those in the Atlantic. And those who bet against America are learning just how wrong they are. It‚Äôs never a good bet to bet against America. When I came to office, most everyone assumed bipartisanship was impossible. But I never believed it. That‚Äôs why a year ago, I offered a Unity Agenda for the nation. We‚Äôve made real progress. Together, we passed a law making it easier for doctors to prescribe effective treatments for opioid addiction. Passed a gun safety law making historic investments in mental health. Launched ARPA-H to drive breakthroughs in the fight against cancer,Alzheimer‚Äôs, diabetes, and so much more. We passed the Heath Robinson PACT Act, named for the late Iraq war veteran whose story about exposure to toxic burn pits I shared here last year. But there is so much more to do. And we can do it together. Joining us tonight is a father named Doug from Newton, New Hampshire. He wrote Jill and me a letter about his daughter Courtney. Contagious laugh. Her sister‚Äôs best friend. He shared a story all too familiar to millions of Americans. Courtney discovered pills in high school. It spiraled into addiction and eventually her death from a fentanyl overdose. She was 20 years old. Describing the last eight years without her, Doug said, ‚ÄúThere is no worse pain.‚Äù Yet their family has turned pain into purpose, working to end stigma and change laws. He told us he wants to ‚Äústart the journey towards America‚Äôs recovery.‚Äù Doug, we‚Äôre with you. Fentanyl is killing more than 70,000 Americans a year. Let‚Äôs launch a major surge to stop fentanyl production, sale, and trafficking, with more drug detection machines to inspect cargo and stop pills and powder at the border. Working with couriers like Fed Ex to inspect more packages for drugs. Strong penalties to crack down on fentanyl trafficking. Second, let‚Äôs do more on mental health, especially for our children. When millions of young people are struggling with bullying, violence, trauma, we owe them greater access to mental health care at school. We must finally hold social media companies accountable for the experiment they are running on our children for profit. And it‚Äôs time to pass bipartisan legislation to stop Big Tech from collecting personal data on kids and teenagers online, ban targeted advertising to children, and impose stricter limits on the personal data these companies collect on all of us. Third, let‚Äôs do more to keep our nation‚Äôs one truly sacred obligation: to equip those we send into harm‚Äôs way and care for them and their families when they come home. Job training and job placement for veterans and their spouses as they return to civilian life. Helping veterans afford their rent because no one should be homeless in this country, especially not those who served it. And we cannot go on losing 17 veterans a day to the silent scourge of suicide. The VA is doing everything it can, including expanding mental health screenings and a proven program that recruits veterans to help other veterans understand what they‚Äôre going through and get the help they need. And fourth, last year Jill and I re-ignited the Cancer Moonshot that President Obama asked me to lead in our Administration. Our goal is to cut the cancer death rate by at least 50% over the next 25 years. Turn more cancers from death sentences into treatable diseases. And provide more support for patients and families. It‚Äôs personal for so many of us. Joining us are Maurice and Kandice, an Irishman and a daughter of immigrants from Panama. They met and fell in love in New York City and got married in the same chapel as Jill and I did. Kindred spirits. He wrote us a letter about their little daughter Ava. She was just a year old when she was diagnosed with a rare kidney cancer. 26 blood transfusions. 11 rounds of radiation. 8 rounds of chemo. 1 kidney removed. A 5% survival rate. He wrote how in the darkest moments he thought, ‚Äúif she goes, I can‚Äôt stay.‚Äù Jill and I understand, like so many of you. They read how Jill described our family‚Äôs cancer journey and how we tried to steal moments of joy where you can. For them, that glimmer of joy was a half-smile from their baby girl. It meant everything. They never gave up hope. Ava never gave up hope. She turns four next month. They just found out that Ava beat the odds and is on her way to being cancer free, and she‚Äôs watching from the White House tonight. For the lives we can save and for the lives we have lost, let this be a truly American moment that rallies the country and the world together and proves that we can do big things. Twenty years ago, under the leadership of President Bush and countless advocates and champions, we undertook a bipartisan effort through PEPFAR to transform the global fight against HIV/AIDS. It‚Äôs been a huge success. I believe we can do the same with cancer. Let‚Äôs end cancer as we know it and cure some cancers once and for all. There‚Äôs one reason why we‚Äôre able to do all of these things: our democracy itself. It‚Äôs the most fundamental thing of all. With democracy, everything is possible. Without it, nothing is. For the last few years our democracy has been threatened, attacked, and put at risk. Put to the test here, in this very room, on January 6th. And then, just a few months ago, unhinged by the Big Lie, an assailant unleashed political violence in the home of the then-Speaker of this House of Representatives. Using the very same language that insurrectionists who stalked these halls chanted on January 6th. Here tonight in this chamber is the man who bears the scars of that brutal attack, but is as tough and strong and as resilient as they get. My friend, Paul Pelosi. But such a heinous act never should have happened. We must all speak out. There is no place for political violence in America. In America, we must protect the right to vote, not suppress that fundamental right. We honor the results of our elections, not subvert the will of the people. We must uphold the rule of the law and restore trust in our institutions of democracy. And we must give hate and extremism in any form no safe harbor. Democracy must not be a partisan issue. It must be an American issue. Every generation of Americans has faced a moment where they have been called on to protect our democracy, to defend it, to stand up for it. And this is our moment. My fellow Americans, we meet tonight at an inflection point. One of those moments that only a few generations ever face, where the decisions we make now will decide the course of this nation and of the world for decades to come. We are not bystanders to history. We are not powerless before the forces that confront us. It is within our power, of We the People. We are facing the test of our time and the time for choosing is at hand. We must be the nation we have always been at our best. Optimistic. Hopeful. Forward-looking. A nation that embraces, light over darkness, hope over fear, unity over division. Stability over chaos. We must see each other not as enemies, but as fellow Americans. We are a good people, the only nation in the world built on an idea. That all of us, every one of us, is created equal in the image of God. A nation that stands as a beacon to the world. A nation in a new age of possibilities. So I have come here to fulfil my constitutional duty to report on the state of the union. And here is my report. Because the soul of this nation is strong, because the backbone of this nation is strong, because the people of this nation are strong, the State of the Union is strong. As I stand here tonight, I have never been more optimistic about the future of America. We just have to remember who we are. We are the United States of America and there is nothing, nothingbeyond our capacity if we do it together. May God bless you all. May God protect our troops.', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'})]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnZjwPa0Wuc8"
      },
      "source": [
        "**Split data in chunks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOUp3oUuWzNY"
      },
      "source": [
        "We split data in chunks using a recursive character text splitter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S1Gz-BLCWovt"
      },
      "outputs": [],
      "source": [
        "# Create an instance of RecursiveCharacterTextSplitter\n",
        "# chunk_size=1000 specifies that each chunk should have a maximum of 1000 characters\n",
        "# chunk_overlap=20 ensures that there is a 20-character overlap between consecutive chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "\n",
        "# Split the input documents into smaller chunks based on the specified chunk size and overlap\n",
        "all_splits = text_splitter.split_documents(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BRM519H2W5im",
        "outputId": "af68c15d-276b-443e-e67a-c49063cf367a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='Mr. Speaker. Madam Vice President. Our First Lady and Second Gentleman. Members of Congress and the Cabinet. Leaders of our military. Mr. Chief Justice, Associate Justices, and retired Justices of the Supreme Court. And you, my fellow Americans. I start tonight by congratulating the members of the 118th Congress and the new Speaker of the House, Kevin McCarthy. Mr. Speaker, I look forward to working together. I also want to congratulate the new leader of the House Democrats and the first Black House Minority Leader in history, Hakeem Jeffries. Congratulations to the longest serving Senate Leader in history, Mitch McConnell. And congratulations to Chuck Schumer for another term as Senate Majority Leader, this time with an even bigger majority. And I want to give special recognition to someone who I think will be considered the greatest Speaker in the history of this country, Nancy Pelosi. The story of America is a story of progress and resilience. Of always moving forward. Of never', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='forward. Of never giving up. A story that is unique among all nations. We are the only country that has emerged from every crisis stronger than when we entered it. That is what we are doing again. Two years ago, our economy was reeling. As I stand here tonight, we have created a record 12 million new jobs, more jobs created in two years than any president has ever created in four years. Two years ago, COVID had shut down our businesses, closed our schools, and robbed us of so much. Today, COVID no longer controls our lives. And two years ago, our democracy faced its greatest threat since the Civil War. Today, though bruised, our democracy remains unbowed and unbroken. As we gather here tonight, we are writing the next chapter in the great American story, a story of progress and resilience. When world leaders ask me to define America, I define our country in one word: Possibilities. You know, we‚Äôre often told that Democrats and Republicans can‚Äôt work together. But over these past two', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='over these past two years, we proved the cynics and the naysayers wrong. Yes, we disagreed plenty. And yes, there were times when Democrats had to go it alone. But time and again, Democrats and Republicans came together. Came together to defend a stronger and safer Europe. Came together to pass a once-in-a-generation infrastructure law, building bridges to connect our nation and people. Came together to pass one of the most significant laws ever, helping veterans exposed to toxic burn pits. In fact, I signed over 300 bipartisan laws since becoming President. From reauthorizing the Violence Against Women Act, to the Electoral Count Reform Act, to the Respect for Marriage Act that protects the right to marry the person you love. To my Republican friends, if we could work together in the last Congress, there is no reason we can‚Äôt work together in this new Congress. The people sent us a clear message. Fighting for the sake of fighting, power for the sake of power, conflict for the sake of', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='for the sake of conflict, gets us nowhere. And that‚Äôs always been my vision for our country. To restore the soul of the nation. To rebuild the backbone of America, the middle class. To unite the country. We‚Äôve been sent here to finish the job. For decades, the middle class was hollowed out. Too many good-paying manufacturing jobs moved overseas. Factories at home closed down. Once-thriving cities and towns became shadows of what they used to be. And along the way, something else was lost. Pride. That sense of self-worth. I ran for President to fundamentally change things, to make sure the economy works for everyone so we can all feel pride in what we do. To build an economy from the bottom up and the middle out, not from the top down. Because when the middle class does well, the poor have a ladder up and the wealthy still do very well. We all do well. As my Dad used to say, a job is about a lot more than a paycheck. It‚Äôs about your dignity. It‚Äôs about respect. It‚Äôs about being able to', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='about being able to look your kid in the eye and say, ‚ÄúHoney ‚Äìit‚Äôs going to be OK,‚Äù and mean it. So, let‚Äôs look at the results. Unemployment rate at 3.4%, a 50-year low. Near record low unemployment for Black and Hispanic workers. We‚Äôve already created 800,000 good-paying manufacturing jobs, the fastest growth in 40 years. Where is it written that America can‚Äôt lead the world in manufacturing again? For too many decades, we imported products and exported jobs. Now, thanks to all we‚Äôve done, we‚Äôre exporting American products and creating American jobs. Inflation has been a global problem because of the pandemic that disrupted supply chains and Putin‚Äôs war that disrupted energy and food supplies. But we‚Äôre better positioned than any country on Earth. We have more to do, but here at home, inflation is coming down. Here at home, gas prices are down $1.50 a gallon since their peak. Food inflation is coming down. Inflation has fallen every month for the last six months while take home pay', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='while take home pay has gone up. Additionally, over the last two years, a record 10 million Americans applied to start a new small business. Every time somebody starts a small business, it‚Äôs an act of hope. And the Vice President will continue her work to ensure more small businesses can access capital and the historic laws we enacted. Standing here last year, I shared with you a story of American genius and possibility. Semiconductors, the small computer chips the size of your fingertip that power everything from cellphones to automobiles, and so much more. These chips were invented right here in America. America used to make nearly 40% of the world‚Äôs chips. But in the last few decades, we lost our edge and we‚Äôre down to producing only 10%. We all saw what happened during the pandemic when chip factories overseas shut down. Today‚Äôs automobiles need up to 3,000 chips each, but American automakers couldn‚Äôt make enough cars because there weren‚Äôt enough chips. Car prices went up. So did', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='went up. So did everything from refrigerators to cellphones. We can never let that happen again. That‚Äôs why we came together to pass the bipartisan CHIPS and Science Act. We‚Äôre making sure the supply chain for America begins in America. We‚Äôve already created 800,000 manufacturing jobs even without this law. With this new law, we will create hundreds of thousands of new jobs across the country. That‚Äôs going to come from companies that have announced more than $300 billion in investments in American manufacturing in the last two years. Outside of Columbus, Ohio, Intel is building semiconductor factories on a thousand acres ‚Äì a literal field of dreams. That‚Äôll create 10,000 jobs. 7,000 construction jobs. 3,000 jobs once the factories are finished. Jobs paying $130,000 a year, and many don‚Äôt require a college degree. Jobs where people don‚Äôt have to leave home in search of opportunity. And it‚Äôs just getting started. Think about the new homes, new small businesses, and so much more that', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='so much more that will come to life. Talk to mayors and Governors, Democrats and Republicans, and they‚Äôll tell you what this means to their communities. We‚Äôre seeing these fields of dreams transform the heartland. But to maintain the strongest economy in the world, we also need the best infrastructure in the world. We used to be #1 in the world in infrastructure, then we fell to #13th. Now we‚Äôre coming back because we came together to pass the Bipartisan Infrastructure Law, the largest investment in infrastructure since President Eisenhower‚Äôs Interstate Highway System. Already, we‚Äôve funded over 20,000 projects, including at major airports from Boston to Atlanta to Portland. These projects will put hundreds of thousands of people to work rebuilding our highways, bridges, railroads, tunnels, ports and airports, clean water, and high-speed internet across America. Urban. Suburban. Rural. Tribal. And we‚Äôre just getting started. I sincerely thank my Republican friends who voted for the', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='who voted for the law. And to my Republican friends who voted against it but still ask to fund projects in their districts, don‚Äôt worry. I promised to be the president for all Americans. We‚Äôll fund your projects. And I‚Äôll see you at the ground-breaking. This law will help further unite all of America. Major projects like the Brent Spence bridge between Kentucky and Ohio over the Ohio River. Built 60 years ago. Badly in need of repairs. One of the nation‚Äôs most congested freight routes carrying $2 billion worth of freight every day. Folks have been talking about fixing it for decades, but we‚Äôre finally going to get it done. I went there last month with Democrats and Republicans from both states to deliver $1.6 billion for this project. While I was there, I met an ironworker named Sara, who is here tonight. For 30 years, she‚Äôs been a proud member of Ironworkers Local 44, known as the ‚Äúcowboys of the sky‚Äù who built the Cincinnati skyline. Sara said she can‚Äôt wait to be ten stories above', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='ten stories above the Ohio River building that new bridge. That‚Äôs pride. That‚Äôs what we‚Äôre also building ‚Äì Pride. We‚Äôre also replacing poisonous lead pipes that go into 10 million homes and 400,000 schools and childcare centers, so every child in America can drink clean water. We‚Äôre making sure that every community has access to affordable, high-speed internet. No parent should have to drive to a McDonald‚Äôs parking lot so their kid can do their homework online. And when we do these projects, we‚Äôre going to Buy American. Buy American has been the law of the land since 1933. But for too long, past administrations have found ways to get around it. Not anymore. Tonight, I‚Äôm also announcing new standards to require all construction materials used in federal infrastructure projects to be made in America. American-made lumber, glass, drywall, fiber optic cables. And on my watch, American roads, American bridges, and American highways will be made with American products. My economic plan is', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='My economic plan is about investing in places and people that have been forgotten. Amid the economic upheaval of the past four decades, too many people have been left behind or treated like they‚Äôre invisible. Maybe that‚Äôs you, watching at home. You remember the jobs that went away. And you wonder whether a path even exists anymore for you and your children to get ahead without moving away. I get it. That‚Äôs why we‚Äôre building an economy where no one is left behind. Jobs are coming back, pride is coming back, because of the choices we made in the last two years. This is a blue-collar blueprint to rebuild America and make a real difference in your lives. For example, too many of you lay in bed at night staring at the ceiling, wondering what will happen if your spouse gets cancer, your child gets sick, or if something happens to you. Will you have the money to pay your medical bills? Will you have to sell the house? I get it. With the Inflation Reduction Act that I signed into law, we‚Äôre', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='into law, we‚Äôre taking on powerful interests to bring your health care costs down so you can sleep better at night. You know, we pay more for prescription drugs than any major country on Earth. For example, one in ten Americans has diabetes. Every day, millions need insulin to control their diabetes so they can stay alive. Insulin has been around for 100 years. It costs drug companies just $10 a vial to make. But, Big Pharma has been unfairly charging people hundreds of dollars ‚Äì and making record profits. Not anymore. We capped the cost of insulin at $35 a month for seniors on Medicare. But there are millions of other Americans who are not on Medicare, including 200,000 young people with Type I diabetes who need insulin to save their lives. Let‚Äôs finish the job this time. Let‚Äôs cap the cost of insulin at $35 a month for every American who needs it. This law also caps out-of-pocket drug costs for seniors on Medicare at a maximum $2,000 per year when there are in fact many drugs, like', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='many drugs, like expensive cancer drugs, that can cost up to $10,000, $12,000, and $14,000 a year. If drug prices rise faster than inflation, drug companies will have to pay Medicare back the difference. And we‚Äôre finally giving Medicare the power to negotiate drug prices. Bringing down prescription drug costs doesn‚Äôt just save seniors money. It will cut the federal deficit, saving tax payers hundreds of billions of dollars on the prescription drugs the government buys for Medicare. Why wouldn‚Äôt we want to do that? Now, some members here are threatening to repeal the Inflation Reduction Act. Make no mistake, if you try to do anything to raise the cost of prescription drugs, I will veto it. I‚Äôm pleased to say that more Americans have health insurance now than ever in history. A record 16 million people are enrolled under the Affordable Care Act. Thanks to the law I signed last year, millions are saving $800 a year on their premiums. But the way that law was written, that benefit', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='that benefit expires after 2025. Let‚Äôs finish the job, make those savings permanent, and expand coverage to those left off Medicaid. Look, the Inflation Reduction Act is also the most significant investment ever to tackle the climate crisis. Lowering utility bills, creating American jobs, and leading the world to a clean energy future. I‚Äôve visited the devastating aftermaths of record floods and droughts, storms and wildfires. In addition to emergency recovery from Puerto Rico to Florida to Idaho, we are rebuilding for the long term. New electric grids able to weather the next major storm. Roads and water systems to withstand the next big flood. Clean energy to cut pollution and create jobs in communities too often left behind. We‚Äôre building 500,000 electric vehicle charging stations installed across the country by tens of thousands of IBEW workers. And helping families save more than $1,000 a year with tax credits for the purchase of electric vehicles and energy-efficient', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='energy-efficient appliances. Historic conservation efforts to be responsible stewards of our lands. Let‚Äôs face reality. The climate crisis doesn‚Äôt care if your state is red or blue. It is an existential threat. We have an obligation to our children and grandchildren to confront it. I‚Äôm proud of how America is at last stepping up to the challenge. But there‚Äôs so much more to do. We will finish the job. And we pay for these investments in our future by finally making the wealthiest and the biggest corporations begin to pay their fair share. I‚Äôm a capitalist. But just pay your fair share. And I think a lot of you at home agree with me that our present tax system is simply unfair. The idea that in 2020, 55 of the biggest companies in America made $40 billion in profits and paid zero in federal income taxes? That‚Äôs simply not fair. But now, because of the law I signed, billion-dollar companies have to pay a minimum of 15%. Just 15%. That‚Äôs less than a nurse pays. Let me be clear. Under my', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='be clear. Under my plan, nobody earning less than $400,000 a year will pay an additional penny in taxes. Nobody. Not one penny. But there‚Äôs more to do. Let‚Äôs finish the job. Reward work, not just wealth. Pass my proposal for a billionaire minimum tax. Because no billionaire should pay a lower tax rate than a school teacher or a firefighter. You may have noticed that Big Oil just reported record profits. Last year, they made $200 billion in the midst of a global energy crisis. It‚Äôs outrageous. They invested too little of that profit to increase domestic production and keep gas prices down. Instead, they used those record profits to buy back their own stock, rewarding their CEOs and shareholders. Corporations ought to do the right thing. That‚Äôs why I propose that we quadruple the tax on corporate stock buybacks to encourage long term investments instead. They will still make a considerable profit. Let‚Äôs finish the job and close the loopholes that allow the very wealthy to avoid paying', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='to avoid paying their taxes. Instead of cutting the number of audits of wealthy tax payers, I signed a law that will reduce the deficit by $114 billion by cracking down on wealthy tax cheats. That‚Äôs being fiscally responsible. In the last two years, my administration cut the deficit by more than $1.7 trillion ‚Äì the largest deficit reduction in American history. Under the previous administration, America‚Äôs deficit went up four years in a row. Because of those record deficits, no president added more to the national debt in any four years than my predecessor. Nearly 25% of the entire national debt, a debt that took 200 years to accumulate, was added by that administration alone. How did Congress respond to all that debt? They lifted the debt ceiling three times without preconditions or crisis. They paid America‚Äôs bills to prevent economic disaster for our country. Tonight, I‚Äôm asking this Congress to follow suit. Let us commit here tonight that the full faith and credit of the United', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='of the United States of America will never, ever be questioned. Some of my Republican friends want to take the economy hostage unless I agree to their economic plans. All of you at home should know what their plans are. Instead of making the wealthy pay their fair share, some Republicans want Medicare and Social Security to sunset every five years. That means if Congress doesn‚Äôt vote to keep them, those programs will go away. Other Republicans say if we don‚Äôt cut Social Security and Medicare, they‚Äôll let America default on its debt for the first time in our history. I won‚Äôt let that happen. Social Security and Medicare are a lifeline for millions of seniors. Americans have been paying into them with every single paycheck since they started working. So tonight, let‚Äôs all agree to stand up for seniors. Stand up and show them we will not cut Social Security. We will not cut Medicare. Those benefits belong to the American people. They earned them. If anyone tries to cut Social Security, I', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='Social Security, I will stop them. And if anyone tries to cut Medicare, I will stop them. I will not allow them to be taken away. Not today. Not tomorrow. Not ever. Next month when I offer my fiscal plan, I ask my Republican friends to offer their plan. We can sit down together and discuss both plans together. My plan will lower the deficit by $2 trillion. I won‚Äôt cut a single Social Security or Medicare benefit. In fact, I will extend the Medicare Trust Fund by at least two decades. I will not raise taxes on anyone making under $400,000 a year. And I will pay for the ideas I‚Äôve talked about tonight by making the wealthy and big corporations begin to pay their fair share. Look, here‚Äôs the deal. Big corporations aren‚Äôt just taking advantage of the tax code. They‚Äôre taking advantage of you, the American consumer. Here‚Äôs my message to all of you out there: I have your back. We‚Äôre already preventing insurance companies from sending surprise medical bills, stopping 1 million surprise bills', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='surprise bills a month. We‚Äôre protecting seniors‚Äô lives and life savings by cracking down on nursing homes that commit fraud, endanger patient safety, or prescribe drugs they don‚Äôt need. Millions of Americans can now save thousands of dollars because they can finally get hearing aids over-the-counter without a prescription. Capitalism without competition is not capitalism. It is exploitation. Last year I cracked down on foreign shipping companies that were making you pay higher prices for everyday goods coming into our country. I signed a bipartisan bill that cut shipping costs by 90%, helping American farmers, businesses, and consumers. Let‚Äôs finish the job. Pass bipartisan legislation to strengthen antitrust enforcement and prevent big online platforms from giving their own products an unfair advantage. My administration is also taking on ‚Äújunk‚Äù fees, those hidden surcharges too many businesses use to make you pay more. For example, we‚Äôre making airlines show you the full ticket', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='you the full ticket price upfront and refund your money if your flight is cancelled or delayed. We‚Äôve reduced exorbitant bank overdraft fees, saving consumers more than $1 billion a year. We‚Äôre cutting credit card late fees by 75%, from $30 to $8. Junk fees may not matter to the very wealthy, but they matter to most folks in homes like the one I grew up in. They add up to hundreds of dollars a month. They make it harder for you to pay the bills or afford that family trip. I know how unfair it feels when a company overcharges you and gets away with it. Not anymore. We‚Äôve written a bill to stop all that. It‚Äôs called the Junk Fee Prevention Act. We‚Äôll ban surprise ‚Äúresort fees‚Äù that hotels tack on to your bill. These fees can cost you up to $90 a night at hotels that aren‚Äôt even resorts. We‚Äôll make cable internet and cellphone companies stop charging you up to $200 or more when you decide to switch to another provider. We‚Äôll cap service fees on tickets to concerts and sporting events and', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='sporting events and make companies disclose all fees upfront. And we‚Äôll prohibit airlines from charging up to $50 roundtrip for families just to sit together. Baggage fees are bad enough ‚Äì they can‚Äôt just treat your child like a piece of luggage. Americans are tired of being played for suckers. Pass the Junk Fee Prevention Act so companies stop ripping us off. For too long, workers have been getting stiffed. Not anymore. We‚Äôre beginning to restore the dignity of work. For example, 30 million workers had to sign non-compete agreements when they took a job. So a cashier at a burger place can‚Äôt cross the street to take the same job at another burger place to make a couple bucks more. Not anymore. We‚Äôre banning those agreements so companies have to compete for workers and pay them what they‚Äôre worth. I‚Äôm so sick and tired of companies breaking the law by preventing workers from organizing. Pass the PRO Act because workers have a right to form a union. And let‚Äôs guarantee all workers a', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='all workers a living wage. Let‚Äôs also make sure working parents can afford to raise a family with sick days, paid family and medical leave, and affordable child care that will enable millions more people to go to work. Let‚Äôs also restore the full Child Tax Credit, which gave tens of millions of parents some breathing room and cut child poverty in half, to the lowest level in history. And by the way, when we do all of these things, we increase productivity. We increase economic growth. Let‚Äôs also finish the job and get more families access to affordable and quality housing. Let‚Äôs get seniors who want to stay in their homes the care they need to do so. And give a little more breathing room to millions of family caregivers looking after their loved ones. Pass my plan so we get seniors and people with disabilities the home care services they need and support the workers who are doing God‚Äôs work. These plans are fully paid for and we can afford to do them. Restoring the dignity of work', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='the dignity of work also means making education an affordable ticket to the middle class. When we made 12 years of public education universal in the last century, it made us the best-educated, best-prepared nation in the world. But the world has caught up. Jill, who teaches full-time, has an expression: ‚ÄúAny nation that out-educates us will out-compete us.‚Äù Folks, you all know 12 years is not enough to win the economic competition for the 21st Century. If you want America to have the best-educated workforce, let‚Äôs finish the job by providing access to pre-school for 3- and 4-year-olds. Studies show that children who go to pre-school are nearly 50% more likely to finish high school and go on to earn a 2- or 4-year degree, no matter their background. Let‚Äôs give public school teachers a raise. And we‚Äôre making progress by reducing student debt and increasing Pell Grants for working- and middle-class families. Let‚Äôs finish the job, connect students to career opportunities starting in high', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='starting in high school and provide two years of community college, some of the best career training in America, in addition to being a pathway to a four-year degree. Let‚Äôs offer every American the path to a good career whether they go to college or not. And folks, in the midst of the COVID crisis when schools were closed, let‚Äôs also recognize how far we‚Äôve come in the fight against the pandemic itself. While the virus is not gone, thanks to the resilience of the American people, we have broken COVID‚Äôs grip on us. COVID deaths are down nearly 90%. We‚Äôve saved millions of lives and opened our country back up. And soon we‚Äôll end the public health emergency. But we will remember the toll and pain that will never go away for so many. More than 1 million Americans have lost their lives to COVID. Families grieving. Children orphaned. Empty chairs at the dining room table. We remember them, and we remain vigilant. We still need to monitor dozens of variants and support new vaccines and', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='new vaccines and treatments. So Congress needs to fund these efforts and keep America safe. And as we emerge from this crisis stronger, I‚Äôm also doubling down on prosecuting criminals who stole relief money meant to keep workers and small businesses afloat during the pandemic. Before I came to office many inspector generals who protect taxpayer dollars were sidelined. Fraud was rampant. Last year, I told you the watchdogs are back. Since then, we‚Äôve recovered billions of taxpayer dollars. Now, let‚Äôs triple our anti-fraud strike forces going after these criminals, double the statute of limitations on these crimes, and crack down on identity fraud by criminal syndicates stealing billions of dollars from the American people. For every dollar we put into fighting fraud, taxpayers get back at least ten times as much. COVID left other scars, like the spike in violent crime in 2020, the first year of the pandemic. We have an obligation to make sure all our people are safe. Public safety', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='safe. Public safety depends on public trust. But too often that trust is violated. Joining us tonight are the parents of Tyre Nichols, who had to bury him just last week. There are no words to describe the heartbreak and grief of losing a child. But imagine what it‚Äôs like to lose a child at the hands of the law. Imagine having to worry whether your son or daughter will come home from walking down the street or playing in the park or just driving their car. I‚Äôve never had to have the talk with my children ‚Äì Beau, Hunter, and Ashley ‚Äì that so many Black and Brown families have had with their children. If a police officer pulls you over, turn on your interior lights. Don‚Äôt reach for your license. Keep your hands on the steering wheel. Imagine having to worry like that every day in America. Here‚Äôs what Tyre‚Äôs mom shared with me when I asked her how she finds the courage to carry on and speak out. With faith in God, she said her son ‚Äúwas a beautiful soul and something good will come from', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='good will come from this.‚Äù Imagine how much courage and character that takes. It‚Äôs up to us. It‚Äôs up to all of us. We all want the same thing. Neighborhoods free of violence. Law enforcement who earn the community‚Äôs trust. Our children to come home safely. Equal protection under the law; that‚Äôs the covenant we have with each other in America. And we know police officers put their lives on the line every day, and we ask them to do too much. To be counselors, social workers, psychologists; responding to drug overdoses, mental health crises, and more. We ask too much of them. I know most cops are good, decent people. They risk their lives every time they put on that shield. But what happened to Tyre in Memphis happens too often. We have to do better. Give law enforcement the training they need, hold them to higher standards, and help them succeed in keeping everyone safe. We also need more first responders and other professionals to address growing mental health and substance abuse', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='and substance abuse challenges. More resources to reduce violent crime and gun crime; more community intervention programs; more investments in housing, education, and job training. All this can help prevent violence in the first place. And when police officers or departments violate the public‚Äôs trust, we must hold them accountable. With the support of families of victims, civil rights groups, and law enforcement, I signed an executive order for all federal officers banning chokeholds, restricting no-knock warrants, and other key elements of the George Floyd Act. Let‚Äôs commit ourselves to make the words of Tyre‚Äôs mother come true, something good must come from this. All of us in this chamber, we need to rise to this moment. We can‚Äôt turn away. Let‚Äôs do what we know in our hearts we need to do. Let‚Äôs come together and finish the job on police reform. Do something. That was the same plea of parents who lost their children in Uvalde: Do something on gun violence. Thank God we did,', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='Thank God we did, passing the most sweeping gun safety law in three decades. That includes things that the majority of responsible gun owners support, like enhanced background checks for 18 to 21-year-olds and red flag laws keeping guns out of the hands of people who are a danger to themselves and others. But we know our work is not done. Joining us tonight is Brandon Tsay, a 26-year-old hero. Brandon put off his college dreams to stay by his mom‚Äôs side as she was dying from cancer. He now works at a dance studio started by his grandparents. Two weeks ago, during Lunar New Year celebrations, he heard the studio‚Äôs front door close and saw a man pointing a gun at him. He thought he was going to die, but then he thought about the people inside. In that instant, he found the courage to act and wrestled the semi-automatic pistol away from a gunman who had already killed 11 people at another dance studio. He saved lives. It‚Äôs time we do the same as well. Ban assault weapons once and for', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='once and for all. We did it before. I led the fight to ban them in 1994. In the 10 years the ban was law, mass shootings went down. After Republicans let it expire, mass shootings tripled. Let‚Äôs finish the job and ban assault weapons again. And let‚Äôs also come together on immigration and make it a bipartisan issue like it was before. We now have a record number of personnel working to secure the border, arresting 8,000 human smugglers and seizing over 23,000 pounds of fentanyl in just the last several months. Since we launched our new border plan last month, unlawful migration from Cuba, Haiti, Nicaragua, and Venezuela has come down 97%. But America‚Äôs border problems won‚Äôt be fixed until Congress acts. If you won‚Äôt pass my comprehensive immigration reform, at least pass my plan to provide the equipment and officers to secure the border. And a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. Here in the people‚Äôs House, it‚Äôs our duty', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='it‚Äôs our duty to protect all the people‚Äôs rights and freedoms. Congress must restore the right the Supreme Court took away last year and codify Roe v. Wade to protect every woman‚Äôs constitutional right to choose. The Vice President and I are doing everything we can to protect access to reproductive health care and safeguard patient privacy. But already, more than a dozen states are enforcing extreme abortion bans. Make no mistake; if Congress passes a national abortion ban, I will veto it. Let‚Äôs also pass the bipartisan Equality Act to ensure LGBTQ Americans, especially transgender young people, can live with safety and dignity. Our strength is not just the example of our power, but the power of our example. Let‚Äôs remember the world is watching. I spoke from this chamber one year ago, just days after Vladimir Putin unleashed his brutal war against Ukraine. A murderous assault, evoking images of the death and destruction Europe suffered in World War II. Putin‚Äôs invasion has been a test', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='has been a test for the ages. A test for America. A test for the world. Would we stand for the most basic of principles? Would we stand for sovereignty? Would we stand for the right of people to live free from tyranny? Would we stand for the defense of democracy? For such a defense matters to us because it keeps the peace and prevents open season for would-be aggressors to threaten our security and prosperity. One year later, we know the answer. Yes, we would. And yes, we did. Together, we did what America always does at our best. We led. We united NATO and built a global coalition. We stood against Putin‚Äôs aggression. We stood with the Ukrainian people. Tonight, we are once again joined by Ukraine‚Äôs Ambassador to the United States. She represents not just her nation, but the courage of her people. Ambassador, America is united in our support for your country. We will stand with you as long as it takes. Our nation is working for more freedom, more dignity, and more peace,not just in', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='peace,not just in Europe, but everywhere. Before I came to office, the story was about how the People‚Äôs Republic of China was increasing its power and America was falling in the world. Not anymore. I‚Äôve made clear with President Xi that we seek competition, not conflict. I will make no apologies that we are investing to make America strong. Investing in American innovation, in industries that will define the future, and that China‚Äôs government is intent on dominating. Investing in our alliances and working with our allies to protect our advanced technologies so they‚Äôre not used against us. Modernizing our military to safeguard stability and deter aggression. Today, we‚Äôre in the strongest position in decades to compete with China or anyone else in the world. I am committed to work with China where it can advance American interests and benefit the world. But make no mistake: as we made clear last week, if China‚Äôs threatens our sovereignty, we will act to protect our country. And we did.', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='And we did. And let‚Äôs be clear: winning the competition with China should unite all of us. We face serious challenges across the world. But in the past two years, democracies have become stronger, not weaker. Autocracies have grown weaker, not stronger. America is rallying the world again to meet those challenges, from climate and global health, to food insecurity, to terrorism and territorial aggression. Allies are stepping up, spending more and doing more. And bridges are forming between partners in the Pacific and those in the Atlantic. And those who bet against America are learning just how wrong they are. It‚Äôs never a good bet to bet against America. When I came to office, most everyone assumed bipartisanship was impossible. But I never believed it. That‚Äôs why a year ago, I offered a Unity Agenda for the nation. We‚Äôve made real progress. Together, we passed a law making it easier for doctors to prescribe effective treatments for opioid addiction. Passed a gun safety law making', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='safety law making historic investments in mental health. Launched ARPA-H to drive breakthroughs in the fight against cancer,Alzheimer‚Äôs, diabetes, and so much more. We passed the Heath Robinson PACT Act, named for the late Iraq war veteran whose story about exposure to toxic burn pits I shared here last year. But there is so much more to do. And we can do it together. Joining us tonight is a father named Doug from Newton, New Hampshire. He wrote Jill and me a letter about his daughter Courtney. Contagious laugh. Her sister‚Äôs best friend. He shared a story all too familiar to millions of Americans. Courtney discovered pills in high school. It spiraled into addiction and eventually her death from a fentanyl overdose. She was 20 years old. Describing the last eight years without her, Doug said, ‚ÄúThere is no worse pain.‚Äù Yet their family has turned pain into purpose, working to end stigma and change laws. He told us he wants to ‚Äústart the journey towards America‚Äôs recovery.‚Äù Doug, we‚Äôre', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='Doug, we‚Äôre with you. Fentanyl is killing more than 70,000 Americans a year. Let‚Äôs launch a major surge to stop fentanyl production, sale, and trafficking, with more drug detection machines to inspect cargo and stop pills and powder at the border. Working with couriers like Fed Ex to inspect more packages for drugs. Strong penalties to crack down on fentanyl trafficking. Second, let‚Äôs do more on mental health, especially for our children. When millions of young people are struggling with bullying, violence, trauma, we owe them greater access to mental health care at school. We must finally hold social media companies accountable for the experiment they are running on our children for profit. And it‚Äôs time to pass bipartisan legislation to stop Big Tech from collecting personal data on kids and teenagers online, ban targeted advertising to children, and impose stricter limits on the personal data these companies collect on all of us. Third, let‚Äôs do more to keep our nation‚Äôs one truly', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='nation‚Äôs one truly sacred obligation: to equip those we send into harm‚Äôs way and care for them and their families when they come home. Job training and job placement for veterans and their spouses as they return to civilian life. Helping veterans afford their rent because no one should be homeless in this country, especially not those who served it. And we cannot go on losing 17 veterans a day to the silent scourge of suicide. The VA is doing everything it can, including expanding mental health screenings and a proven program that recruits veterans to help other veterans understand what they‚Äôre going through and get the help they need. And fourth, last year Jill and I re-ignited the Cancer Moonshot that President Obama asked me to lead in our Administration. Our goal is to cut the cancer death rate by at least 50% over the next 25 years. Turn more cancers from death sentences into treatable diseases. And provide more support for patients and families. It‚Äôs personal for so many of us.', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='for so many of us. Joining us are Maurice and Kandice, an Irishman and a daughter of immigrants from Panama. They met and fell in love in New York City and got married in the same chapel as Jill and I did. Kindred spirits. He wrote us a letter about their little daughter Ava. She was just a year old when she was diagnosed with a rare kidney cancer. 26 blood transfusions. 11 rounds of radiation. 8 rounds of chemo. 1 kidney removed. A 5% survival rate. He wrote how in the darkest moments he thought, ‚Äúif she goes, I can‚Äôt stay.‚Äù Jill and I understand, like so many of you. They read how Jill described our family‚Äôs cancer journey and how we tried to steal moments of joy where you can. For them, that glimmer of joy was a half-smile from their baby girl. It meant everything. They never gave up hope. Ava never gave up hope. She turns four next month. They just found out that Ava beat the odds and is on her way to being cancer free, and she‚Äôs watching from the White House tonight. For the', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='tonight. For the lives we can save and for the lives we have lost, let this be a truly American moment that rallies the country and the world together and proves that we can do big things. Twenty years ago, under the leadership of President Bush and countless advocates and champions, we undertook a bipartisan effort through PEPFAR to transform the global fight against HIV/AIDS. It‚Äôs been a huge success. I believe we can do the same with cancer. Let‚Äôs end cancer as we know it and cure some cancers once and for all. There‚Äôs one reason why we‚Äôre able to do all of these things: our democracy itself. It‚Äôs the most fundamental thing of all. With democracy, everything is possible. Without it, nothing is. For the last few years our democracy has been threatened, attacked, and put at risk. Put to the test here, in this very room, on January 6th. And then, just a few months ago, unhinged by the Big Lie, an assailant unleashed political violence in the home of the then-Speaker of this House of', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='of this House of Representatives. Using the very same language that insurrectionists who stalked these halls chanted on January 6th. Here tonight in this chamber is the man who bears the scars of that brutal attack, but is as tough and strong and as resilient as they get. My friend, Paul Pelosi. But such a heinous act never should have happened. We must all speak out. There is no place for political violence in America. In America, we must protect the right to vote, not suppress that fundamental right. We honor the results of our elections, not subvert the will of the people. We must uphold the rule of the law and restore trust in our institutions of democracy. And we must give hate and extremism in any form no safe harbor. Democracy must not be a partisan issue. It must be an American issue. Every generation of Americans has faced a moment where they have been called on to protect our democracy, to defend it, to stand up for it. And this is our moment. My fellow Americans, we meet', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='Americans, we meet tonight at an inflection point. One of those moments that only a few generations ever face, where the decisions we make now will decide the course of this nation and of the world for decades to come. We are not bystanders to history. We are not powerless before the forces that confront us. It is within our power, of We the People. We are facing the test of our time and the time for choosing is at hand. We must be the nation we have always been at our best. Optimistic. Hopeful. Forward-looking. A nation that embraces, light over darkness, hope over fear, unity over division. Stability over chaos. We must see each other not as enemies, but as fellow Americans. We are a good people, the only nation in the world built on an idea. That all of us, every one of us, is created equal in the image of God. A nation that stands as a beacon to the world. A nation in a new age of possibilities. So I have come here to fulfil my constitutional duty to report on the state of the', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'}),\n",
              " Document(page_content='on the state of the union. And here is my report. Because the soul of this nation is strong, because the backbone of this nation is strong, because the people of this nation are strong, the State of the Union is strong. As I stand here tonight, I have never been more optimistic about the future of America. We just have to remember who we are. We are the United States of America and there is nothing, nothingbeyond our capacity if we do it together. May God bless you all. May God protect our troops.', metadata={'source': '/content/biden-sotu-2023-planned-official.txt'})]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX5R5wbpmnkk",
        "outputId": "de8c38b0-aed8-4d80-e478-90f1ba9d9d96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(all_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwziMaj-XA_s"
      },
      "source": [
        "**Creating Embeddings and Storing in Vector Store**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvoJnEzhXDtX"
      },
      "source": [
        "Create the embeddings using Sentence Transformer and HuggingFace embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "fJZlnuxFbGs8"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh_P7qcRhsIg",
        "outputId": "6f2f89c0-8a33-407e-cad2-860739e87f4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2id29d8_mQA8",
        "outputId": "2401218b-63a7-4472-850f-5ef89dcb1405"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(all_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ziGXi657XIpm"
      },
      "outputs": [],
      "source": [
        "# Load spaCy's large English model (pre-trained word vectors)\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "# Define a custom embeddings class based on spaCy\n",
        "class SpacyEmbeddings(Embeddings):  # Inherit from LangChain's Embeddings base class\n",
        "    def __init__(self, model):\n",
        "        \"\"\"Initialize the custom embeddings class with a spaCy model.\"\"\"\n",
        "        self.model = model  # Store the spaCy model instance\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        \"\"\"Embed a list of documents and return a list of lists (instead of NumPy arrays).\"\"\"\n",
        "        return [self.model(text).vector.tolist() for text in texts]  # Convert numpy arrays to lists\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        \"\"\"Embed a single query.\"\"\"\n",
        "        return self.model(text).vector.tolist()  # Convert numpy array to list\n",
        "\n",
        "# Instantiate the embeddings class with the spaCy model\n",
        "spacy_embeddings = SpacyEmbeddings(nlp)\n",
        "\n",
        "# Assuming 'all_splits' is a list of text chunks that need to be embedded\n",
        "document_objects = [Document(page_content=str(chunk)) for chunk in all_splits]\n",
        "# Wrap each text chunk in LangChain's `Document` class and ensure content is a string\n",
        "\n",
        "# Import Chroma vector store\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Create the Chroma vector store using the custom spaCy embeddings class\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=document_objects,  # List of document objects to store\n",
        "    embedding=spacy_embeddings,  # Use the custom spaCy-based embedding class\n",
        "    persist_directory=\"chroma_db\"  # Directory to persist the vector database\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhlacg71oxbG"
      },
      "source": [
        "**Initialize chain**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kOVapxiNjbwz"
      },
      "outputs": [],
      "source": [
        "# Create a retriever object from the vector database, which will be used to search for relevant documents\n",
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "# Create a RetrievalQA object to handle question-answering tasks\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,  # Use the specified language model (LLM) for generating answers\n",
        "    chain_type=\"stuff\",  # The chain type \"stuff\" means all retrieved documents are stuffed into the LLM input\n",
        "    retriever=retriever,  # Attach the retriever to fetch relevant documents\n",
        "    verbose=True  # Enable verbose mode to display additional details during execution\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRGNi9iMo72F"
      },
      "source": [
        "**Test the Retrieval-Augmented Generation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cx8653mo_jC"
      },
      "source": [
        "We define a test function, that will run the query and time it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Se1vmrEmouqF"
      },
      "outputs": [],
      "source": [
        "def test_rag(qa, query):\n",
        "    \"\"\"\n",
        "    Function to test a retrieval-augmented generation (RAG) model.\n",
        "\n",
        "    Parameters:\n",
        "    qa: The RAG model or pipeline that takes a query and returns a response.\n",
        "    query: The input question or prompt for the RAG model.\n",
        "\n",
        "    This function prints the query, measures the inference time, and displays the result.\n",
        "    \"\"\"\n",
        "\n",
        "    # Print the query being tested\n",
        "    print(f\"Query: {query}\\n\")\n",
        "\n",
        "    # Record the start time before inference\n",
        "    time_1 = time()\n",
        "\n",
        "    # Run the query through the RAG model (qa) and store the result\n",
        "    result = qa.run(query)\n",
        "\n",
        "    # Record the end time after inference\n",
        "    time_2 = time()\n",
        "\n",
        "    # Calculate and print the inference time (rounded to 3 decimal places)\n",
        "    print(f\"Inference time: {round(time_2 - time_1, 3)} sec.\")\n",
        "\n",
        "    # Print the retrieved/generated response\n",
        "    print(\"\\nResult: \", result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w8EN-A5pGW-"
      },
      "source": [
        "Let's check few queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Ae6kg7pEJU",
        "outputId": "c40435e6-2485-4ee9-9083-15b435485d36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Inference time: 50.514 sec.\n",
            "\n",
            "Result:   The main topics in the 2023 State of the Union address by President Joe Biden were:\n",
            "\n",
            "* Congratulating new members of Congress and leadership\n",
            "* Recognizing achievements and progress in the country\n",
            "* Addressing the deficit and national debt\n",
            "* Calling for bipartisan cooperation and passing legislation\n",
            "* Highlighting accomplishments of the previous two years\n",
            "* Pushing for permanent expansion of Medicaid coverage\n",
            "* Investing in clean energy and infrastructure\n",
            "* Addressing climate change and natural disasters\n",
            "\n",
            "Overall, President Biden emphasized the need for cooperation and progress in various areas, including healthcare, infrastructure, and the environment.\n"
          ]
        }
      ],
      "source": [
        "query = \"What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\"\n",
        "test_rag(qa, query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8-GKi-bpQRB",
        "outputId": "00668d7e-1131-462c-8f53-ca71d7c8b358"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is the nation economic status? Summarize. Keep it under 200 words.\n",
            "\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Inference time: 19.948 sec.\n",
            "\n",
            "Result:   The nation's economic status is mixed. While the stock market is at an all-time high, many Americans are still struggling to make ends meet. The middle class has been hollowed out, and too many good-paying manufacturing jobs have moved overseas. Factories at home have closed down, and once-thriving cities and towns have become shadows of what they used to be. The climate crisis is an existential threat, and the wealthiest and biggest corporations need to pay their fair share in taxes. The President believes that the country needs to rebuild the backbone of America, the middle class, and unite the country. The President also believes that the present tax system is unfair and needs to be changed.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the nation economic status? Summarize. Keep it under 200 words.\"\n",
        "test_rag(qa, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf-Z7K-Kplbw"
      },
      "source": [
        "**Document sources**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACoGuDNrphQ8",
        "outputId": "40244bd2-b295-4346-c1d0-13a16149d98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: What is the nation economic status? Summarize. Keep it under 200 words.\n",
            "Retrieved documents: 4\n"
          ]
        }
      ],
      "source": [
        "docs = vectordb.similarity_search(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Retrieved documents: {len(docs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zz0MpI0ew4x"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R63Jfz9dfKOJ"
      },
      "source": [
        "# Download necessary libraries used in running this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xXJZIsQrewip",
        "outputId": "0a7afac4-1195-4a03-f94f-354e942f2ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered requirements.txt created successfully!\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_2bbe1517-06d8-450e-a0c0-53475416e5a0\", \"requirements.txt\", 2322)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import sys\n",
        "import pkgutil\n",
        "import importlib\n",
        "import pip\n",
        "\n",
        "# Get all modules currently loaded in the notebook\n",
        "loaded_modules = {name for _, name, _ in pkgutil.iter_modules()}\n",
        "\n",
        "# Get all imported modules in the notebook\n",
        "imported_modules = {module for module in sys.modules.keys() if module in loaded_modules}\n",
        "\n",
        "# Use importlib.metadata instead of pip.get_installed_distributions()\n",
        "if sys.version_info >= (3, 8):\n",
        "    from importlib import metadata as importlib_metadata\n",
        "else:\n",
        "    import importlib_metadata\n",
        "\n",
        "installed_packages = {dist.name: dist.version for dist in importlib_metadata.distributions()}\n",
        "\n",
        "# Filter the installed packages based on imports\n",
        "required_packages = {pkg: installed_packages[pkg] for pkg in imported_modules if pkg in installed_packages}\n",
        "\n",
        "# Save to requirements.txt\n",
        "with open(\"requirements.txt\", \"w\") as f:\n",
        "    for pkg, version in required_packages.items():\n",
        "        f.write(f\"{pkg}=={version}\\n\")\n",
        "\n",
        "print(\"Filtered requirements.txt created successfully!\")\n",
        "\n",
        "# Download the file\n",
        "from google.colab import files\n",
        "files.download(\"requirements.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3HhEtGvexq2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e85ef268b78445e80cd984c62f64db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24d3c134225342fabcc2c097a2bc2424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_310c962da5a94162a1c0d74dd38af031",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df20603b16f1443d93d9dd58026e0ef7",
            "value": 2
          }
        },
        "283c8cd58ded4feabf2d0a42b7a47df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "310c962da5a94162a1c0d74dd38af031": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73757e578c6149fc83735b71d4aa6964": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc84ed4fab74dd7bed261b2f206469e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ab7fca8b0e4966a39f84b8055cdc84",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_283c8cd58ded4feabf2d0a42b7a47df1",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "9d012603cec24b9b8407797555b209c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ab7fca8b0e4966a39f84b8055cdc84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c5cc5037f544e9a85206fdc947a58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d012603cec24b9b8407797555b209c1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0e85ef268b78445e80cd984c62f64db7",
            "value": "‚Äá2/2‚Äá[01:03&lt;00:00,‚Äá29.30s/it]"
          }
        },
        "df20603b16f1443d93d9dd58026e0ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f59507e1ae7449718146103d3a799681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fc84ed4fab74dd7bed261b2f206469e",
              "IPY_MODEL_24d3c134225342fabcc2c097a2bc2424",
              "IPY_MODEL_d5c5cc5037f544e9a85206fdc947a58f"
            ],
            "layout": "IPY_MODEL_73757e578c6149fc83735b71d4aa6964"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
